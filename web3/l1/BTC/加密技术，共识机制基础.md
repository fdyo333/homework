

# 共识算法

共识算法是分布式系统中维护状态一致性的关键技术，广泛应用于各类系统，如分布式文件系统和分布式数据库。这些算法根据应用场景的具体需求而有所不同，特别是在公链和联盟链的应用中。

在公链中，共识算法需满足高扩展性，确保在节点动态加入网络的情况下，共识流程仍然有效运行，同时防御可能的拜占庭式攻击。由于 FLP 不可能性定理和 CAP 定理的限制，公链的共识算法通常无法提供绝对的一致性保证。

相比之下，联盟链的共识算法则侧重于实现强一致性和高性能。虽然对系统的可扩展性和防御拜占庭节点的攻击力度需求不如公链高，但联盟链仍需确保系统的稳定性和效率。

> 说明： 在本文档中，由于不是关键，所以没有对一致性（Consistency）和共识（Consensus）概念作严格区分，所以读者会看到这两个概念在同一个位置混用的情况。
> 笔者在此根据多方资料对这两个概念先进行解释：
> **一致性**：主要描述的是分布式系统多节点的情况，各节点中某一类元素在不同时刻的对外呈现的状态一致性。其中的「状态」的概念由所在系统定义，如数据库系统中的状态主要指的是数据在事务执行前后的状态。
> 一致性可以分为**顺序一致性、线性一致性、弱一致性**，其中线性一致性也叫做强一致性，最终一致性是弱一致性的特定状态。
> **共识**：主要描述的是分布式系统多个节点，彼此针对某一提案达成一致认识的**过程**。
> 可以大致认为，一致性描述的是**对外呈现**的结果状态，共识描述的是过程。

## 一、背景

### 1. 共识算法简史

共识算法是分布式系统的核心，用于确保不同节点间的数据一致性。下面是共识算法发展简史的概述：

1. 1978 年 - Jim Gray 在其论文中首次提出了**两阶段提交（2PC）**，这是早期尝试解决分布式数据一致性问题的方案。尽管 2PC 能解决一定的一致性问题，但它存在验证的阻塞和脑裂（网络分区）问题。
2. 1981 年 - Dale Skeen 进一步提出**三阶段提交（3PC）**，该算法改进了 2PC 的阻塞问题，但仍存在脑裂和单点故障的问题。
3. 1982 年 - Leslie Lamport 提出了**拜占庭将军问题**，这一理论引入了拜占庭错误的概念，展示了一致性问题的高复杂度，并在其论文中探索了在同步模型下的解决方案。
4. 1985 年 - F, L, P（Fischer, Lynch, Paterson）提出了 **FLP 不可能定理**，明确指出在一个异步网络中，如果至少有一个节点故障，就无法设计出完美的共识算法。
5. 1988 年 - Dwork, Lynch, Stockmeyer 引入了**部分同步模型**，这是一种介于同步和异步之间的网络模型，在该模型下可以在某种程度上绕过 FLP 定理的限制。
6. 1990 年 - Lamport 又提出了 **Paxos 算法** ，这是第一个旨在异步网络中保证安全，并且在网络变为同步时能确保一致性的共识算法。大量后续的共识算法如 Raft，都是基于 Paxos 的变体。
7. 1999 年 - Miguel Castro 和 Barbara Liskov 提出了**PBFT（实用拜占庭容错）**算法，大幅降低了拜占庭容错算法的运行复杂度，成为第一个实用的拜占庭容错算法。
8. 2008 年 - 中本聪发表比特币白皮书，首次提出了比特币概念，并将 **工作量证明（PoW）** 算法应用于区块链。此后，各种新型共识算法如权益证明（PoS）、授权证明（PoA）等相继出现，共识算法从传统分布式系统演化到专为区块链设计。

这一历史梳理不仅展示了共识算法的演变，还揭示了它们如何从解决传统分布式系统的一致性问题，演化到支持现代区块链技术的关键工具。

### 2. 早期数据库系统中的共识机制（分布式一致性方案）

在早期的数据库系统中，为了确保在多节点环境下的事务一致性，设计者们开发了一系列分布式一致性方案，其中最著名的是两阶段提交（2PC）和三阶段提交（3PC）。这些方案主要通过预写式日志机制来实现节点间的事务一致性及故障恢复。预写式日志是一种保证数据完整性的技术，通过在事务正式提交前记录数据的预期变更，确保即使在发生故障时也能恢复到一致的状态。

2PC 和 3PC 的设计初衷是处理节点因工作异常或网络问题而无响应的情况，而不是防御恶意节点的攻击。这意味着它们假设所有节点基本上是诚实的，只是可能会因为技术故障而无法完成其任务。因此，这些协议非常依赖于网络的可靠性和节点的正常运行，一旦遇到网络分区或节点故障，可能会导致事务处理的延迟或阻塞，这在现代分布式系统中可能是一个限制因素。

#### 2.1 两阶段提交（2PC）

在数据库系统中，两阶段提交（2PC）是一种广泛采用的协议，用于保障多个节点参与的事务的一致性。该方法由一个称为事务管理器（TM）的协调节点控制整个事务过程，负责与所有参与的资源管理器（RM）协作，确保事务要么完全提交，要么完全回滚。

**第一阶段**

- 事务管理器（TM）向所有资源管理器（RM）发送“准备好提交事务吗？”的询问。
- 各参与节点回应“是”（Yes）或“否”（No）。

**第二阶段**

- 如果所有参与节点的回应都是“Yes”，则 TM 向所有 RM 广播“提交（Commit）”指令。
- 如果任一节点回应“No”或未在规定时间内回应，则 TM 广播“回滚（Rollback）”指令。
- 完成指令后，参与节点向 TM 发送确认回应（Ack），TM 随后标记事务为已完成。

##### 优点

- 简单有效：2PC 协议结构简单，能够在同步通信系统中有效地保障事务的强一致性。
- 恢复能力：在节点发生故障时，系统会暂停服务，待节点恢复后，系统可继续运行并保持数据的一致性。

##### 缺点

- 阻塞问题：在第一阶段中，所有节点必须锁定其控制的资源，导致这些资源在事务提交期间无法被其他操作访问。
- 脑裂和恢复问题：

  - 在第二阶段，如果部分节点由于网络问题或 TM 故障未接收到指令，会导致临时的数据不一致。这种状态只能在节点与 TM 的通信恢复后才能解决。
  - 如果参与节点在发送完成事务的确认（Ack）之前故障，即使 TM 恢复，也无法确定事务的最终状态，必须等待所有参与节点恢复后才能解决。
- 单点故障：TM 作为中心节点，其故障会导致整个系统阻塞，直到 TM 恢复。

通过这种方式，两阶段提交确保了跨多个分布式节点的事务能够一致地提交或回滚，尽管它面临一些性能和可靠性挑战。

#### 2.2 三阶段提交

为了解决两阶段提交（2PC）中存在的阻塞和潜在的脑裂问题，三阶段提交（3PC）协议被开发出来。该协议通过引入额外的预提交阶段和参与者的超时机制来增强系统的鲁棒性，并使用预写日志来保障节点在故障后能从日志中恢复到正确的状态。

**第一阶段：询问提交**

- 协调节点向所有参与节点发送“CanCommit”指令以询问是否准备好提交事务，同时启动超时计时。
- 若在超时期限内未收到协调节点的下一步指令，参与节点将终止事务。

**第二阶段：预提交**

- 如果所有参与者都回答“Yes”，协调节点随后发出“PreCommit”指令。
- 参与者在将事务的 undo 和 redo 日志写入稳定存储后回复“Yes”或“No”，并在此之后启动另一个超时计时。
- 如果在此阶段超时未收到协调节点的最终指令，参与者将根据自己的预提交状态直接提交事务。

> 预提交是指参与者将事务的 undo 和 redo 日志写入本地的稳定存储介质，但不进行真正提交；同时这里的参与者超时后回滚是与两阶段提交的「阻塞等待」的不同之处。

**第三阶段：最终提交**

- 如果所有参与者在预提交阶段都回复“Yes”，协调节点则发出“DoCommit”指令。
- 参与者收到后执行最终提交，向协调者发送最终的确认响应（Ack）。
- 如果有参与者回答“No”或响应超时，协调节点会指示所有参与者根据 undo 日志回滚事务。

**注意点**

- 如果协调者在最后阶段宕机，那些未收到“DoCommit”指令的参与者将在超时后直接提交事务。
- 如果参与者在收到回滚指令后完成回滚，也需要向协调者发送确认响应（Ack）。

**优点**

- 减少阻塞：通过引入预提交阶段和参与者的超时机制，3PC 减少了参与者因等待协调节点的指令而产生的阻塞。
- 增强决策能力：参与者能根据自己的日志在超时情况下自主决定提交或回滚，增强了系统在协调节点故障时的独立性。

**缺陷**

- 潜在的数据不一致：在网络分区的情况下，已经进入预提交阶段的节点在超时后可能会提交事务，而未接收到预提交指令的节点则会回滚，导致数据不一致。即使网络恢复，新的协调者也难以判断事务的正确状态。

尽管三阶段提交提供了比两阶段提交更高的容错性，但它仍然不能完全解决所有分布式系统中的一致性问题。

#### 2.3 小结

两阶段提交（2PC）和三阶段提交（3PC）通常适用于同步通信的分布式系统。然而，在现实中，许多分布式系统是由通过异步通信方式相连的多个主机组成的集群。在这种异步系统中，常见的挑战包括通信故障、主机性能不足或网络拥堵等，这些因素都可能导致错误信息在系统内部错误地传播。

由于这些问题，传统的两阶段或三阶段提交协议可能不足以应对所有情况，尤其是在网络不可靠的情况下。因此，分布式系统需要依赖更加健壮的共识算法来构建容错协议，这些算法能够在默认不可靠的异步网络环境中确保各个主机之间达成一个安全且可靠的状态共识。

总的来说，为了在分布式系统中实现高效且可靠的状态同步和一致性保障，选择和实施适合的共识算法至关重要。这要求算法不仅能处理正常操作中的协调问题，还能在遇到网络延迟、节点故障等异常情况时保持系统的整体一致性和可靠性。

### 3. 拜占庭将军问题

在讨论拜占庭将军问题之前，重要的是要了解早期的分布式一致性方案如两阶段提交（2PC）和三阶段提交（3PC）的局限性。这些方案虽然模型简单，却存在明显的安全性缺陷，并且假设系统中不存在恶意节点，只能在诚实节点的环境中有效运作。

随着分布式系统的复杂性增加，特别是在可能包含恶意节点的环境中，需要更健壮的共识算法来处理这种情况。拜占庭将军问题正是这类研究的核心。这个问题描述了一种情况，其中系统中的一些节点可能会故意发送错误或矛盾的信息，从而破坏系统的一致性。

拜占庭将军问题是通过以下场景来说明的：若干将军各领一支军队围攻一个城市，他们只能通过信使传递信息。为了成功攻占城市，所有将军必须同意攻击或撤退的统一行动计划。然而，一些将军可能是叛徒，会故意发送虚假信息以迷惑其他忠诚的将军。解决这一问题的算法必须能确保即便存在叛徒，忠诚的将军们也能达成一致的决策。

理解拜占庭将军问题对于深入学习和应用共识算法是至关重要的，因为它展示了在存在潜在恶意行为的分布式系统中，如何设计能够抵抗这类攻击的算法。这一问题的解决方案也催生了多种拜占庭容错（BFT）算法，这些算法现在是构建安全可靠的分布式系统和区块链技术的基础。

拜占庭将军问题，是在 1982 年 Leslie Lamport、Robert Shostak、Marshall Pease 三位科学家的论文中提出的。下面贴出论文中的描述(来自维基百科)：

> 一组拜占庭将军分别各率领一支军队共同围困一座城市。为了简化问题，将各支军队的行动策略限定为**进攻或撤离**两种。因为部分军队进攻部分军队撤离可能会造成
> 灾难性后果，因此各位将军必须通过投票来达成一致策略，即所有军队一起进攻或所有军队一起撤离。因为各位将军分处城市不同方向，他们只能通过信使互相联系。
> 在投票过程中每位将军都将自己投票给进攻还是撤退的信息通过信使分别通知其他所有将军，这样一来每位将军根据自己的投票和其他所有将军送来的信息就可以知道
> 共同的投票结果而决定行动策略。

拜占庭将军问题的核心在于如何在可能存在叛徒的情况下，确保系统的一致性。这个问题通过一个示例来说明，其中涉及 9 位将军投票决定是否进攻或撤退，但其中可能包括叛徒。

假设这 9 位将军中有 1 位叛徒，剩余 8 位将军中均匀分布了进攻和撤退的投票（各 4 票）。在这种情况下，叛徒的策略可能是选择性地发送信息，以破坏忠诚将军之间的一致性。例如，叛徒可以对那 4 名投票进攻的将军发送信息称自己也投票进攻，同时对那 4 名投票撤退的将军发送信息称自己投票撤退。这种行为导致两个分组中的将军收到的投票信息不一致：

- 对于投票进攻的 4 名将军来说，他们将认为有 5 票支持进攻（包括叛徒的虚假支持），从而倾向于发起进攻。
- 同时，对于投票撤退的 4 名将军来说，他们将认为有 5 票支持撤退（同样包括叛徒的虚假支持），因此倾向于撤退。

这种信息的不对称和叛徒的操纵行为最终导致了军队行动上的不一致，破坏了整体的协同作战计划。这个例子清晰地展示了在分布式系统或区块链网络中，如果不通过有效的共识机制来防范和处理恶意行为，整个系统的稳定性和安全性都可能受到严重威胁。如下图

![](static/A4kYb4a3RogHK3xT5mPcjlajndf.png)

除了叛徒，还可能存在以下问题：

- 叛徒伪造其他将军身份投票
- 即使保证所有将军忠诚，也不能排除信使被敌人截杀或被间谍替换

因此很难通过保证人员可靠性及通讯可靠性来解决问题，只能通过收到的投票情况来做决定。

**问题建模**

在解决拜占庭将军问题的过程中，问题的建模是至关重要的一步。这一问题模型设定了一组将军，其中包括可能的叛徒，需要通过共识来决定共同的行动方案。关键在于找到一种算法，满足以下两个核心条件：

- A. 一致性决策：所有忠诚的将军必须达成相同的决策。
- B. 抵抗叛徒干扰：即使存在叛徒，也不能让他们影响忠诚将军做出错误的决策。

只有同时满足这两个条件，我们才能认为有效解决了拜占庭将军问题。在这方面，三位科学家在他们的论文中提出了两种解决方案：

1. 基于口头消息的协议
2. 基于书面消息的协议

**解法 1：基于口头消息的协议**

这种方案中，为了容忍 m 个叛徒的存在，系统必须至少包括 3m+1 个将军。该协议依赖于以下三个关键前提条件，以确保其正确执行：

- A1: 通信可靠性 — 所有发出的消息必须能被成功地传递到达目的地。
- A2: 身份验证 — 消息接收方必须能够准确地识别出消息的发送方是谁，确保消息的来源不能被伪造。
- A3: 消息丢失检测 — 必须能够检测到消息的丢失，并且有机制进行重发。

这些条件共同定义了一个严格的同步网络环境，其中所有将军之间能够进行直接的点对点通信。下面通过几个例子来简单地理解这个协议的基本思想：

1. n=3 个将军，m=1 个叛徒的情况：

   - 最坏情况：A 是叛徒并且是指令发出者，向 B 和 C 发送撤退指令（错误指令）。B 和 C 没有相互矛盾的信息来质疑 A 的指令，因此最终可能作出错误的撤退决策。
   - 一般情况 1：A 是叛徒并且是指令发出者，向 B 和 C 发送不同的指令。这会导致 B 和 C 收到彼此矛盾的信息，从而无法作出一致的决策。
   - 一般情况 2：A 是叛徒但不是指令发出者（B 是），B 向 A 和 C 发送进攻指令，A 向 C 传达撤退指令。C 收到矛盾指令，无法作出最终决策。
2. n=4 个将军，m=1 个叛徒的情况：

   - 最坏情况：A 是叛徒并且是指令发出者，向 B、C 和 D 发送错误指令 X。B、C 和 D 可能会由于没有足够的信息来识别错误而作出错误决策。
   - 一般情况 1：A 是叛徒并且是指令发出者，向 B 发送正确指令 X，向 C 和 D 发送错误指令 Y。这导致 B、C 和 D 收到混乱的信息，从而可能作出错误决策 Y。
   - 一般情况 2：A 是叛徒并且是指令发出者，向 B、C 和 D 发送不同的指令 XYZ。这导致 B、C 和 D 都收到不同的指令，无法作出最终决策。
   - 一般情况 3：A 是叛徒但不是指令发出者（B 是），B 向 A、C 和 D 发送正确指令 X，A 向 C 和 D 传达错误指令 Y。C 和 D 互相传达后，可以发现 A 的不一致行为，从而判断 A 是叛徒，最终能够作出正确的决策。

这些例子展示了在不同情况下，基于口头消息的协议如何应对可能的叛徒行为，并尝试确保所有忠诚的将军能够达成一致的决策。

**解法 2：基于书面消息的协议**

这种方案设计用于处理 n 个将军中最多有 m 个叛徒的情况，条件是 n 大于或等于 m。在基于口头消息的协议中，一个显著的弱点是它不能防止消息的伪造；如果叛徒能够伪造其他将军的消息且接收方无法识别这一点，那么在最坏的情况下，接收方可能会认为所有收到的消息都是伪造的。这会导致决策的瘫痪，因为将军们无法确定哪些信息是可信的，最终可能只能选择撤退。

为了克服这一挑战，“基于书面消息的协议”引入了消息签名的概念。在这个协议中，每条消息都附带有发送者的签名，接收者可以通过验证这些签名来确保消息的真实性。这种方法使得消息变得不可伪造。在现代计算机网络中，这相当于所有网络消息都附带节点的私钥签名，而其他节点则通过相应的公钥进行验证。

**拜占庭容错（BFT）**

拜占庭容错（BFT）是一种机制，如果能制定出一套方案，使得将军们仅通过评估他们收到的投票信息就能够决定自己的战略，那么这个系统就可以称之为实现了拜占庭容错。这意味着即使在存在恶意行为者的情况下，系统也能保持正常运作，做出正确的集体决策，确保整体的安全和效率。

> 拜占庭错误算是分布式系统中一个最极端的问题，某个算法解决了这个问题，就可以说这个共识算法是足够健壮的。

### 4. 共识系统的基本定义

#### 4.1 关于拜占庭缺陷和故障的 4 个定义

在分布式系统中，对缺陷和故障的定义有助于明确系统的设计和运行标准。以下是拜占庭缺陷和故障的四个主要定义，以及它们在共识系统中的作用和影响：

1. 拜占庭缺陷：这种缺陷的特点是其表现形式因观察者的不同角度而异，显示出不同的症状。这种缺陷的多变性和不可预测性使得它们特别难以处理。
2. 拜占庭故障：当拜占庭缺陷在需要共识的系统中出现，并导致系统服务丧失时，这种情况被称为拜占庭故障。拜占庭故障可能包括数据损坏、恶意软件的干扰，或是恶意节点的任意行为。
3. 宕机缺陷：这种缺陷导致系统中的进程停止运行，但不对系统产生其他副作用。宕机缺陷通常与系统的部分功能失效相关，但不涉及数据损坏或恶意行为。
4. 宕机恢复故障：类似于宕机缺陷，但区别在于当进程重启后，系统能够恢复正常运行，且不会对系统产生其他副作用。这种类型的故障强调了系统在故障后能够自我修复和恢复的能力。

在这样的系统中，一个正确的共识算法必须满足以下三个核心特性：

- 一致性：所有节点必须同意某个决策值，确保系统操作的整体一致性。
- 有效性（正确性）：被所有节点接受的决策值必须由这些节点中的至少一个提出，保证决策的合法性和相关性。
- 终止性（可结束性）：所有节点最终都能完成决策过程，确保系统不会无限期地等待而无法前进。

一致性保证了所有节点在决策上的一致；有效性确保了决策的实际意义和应用价值；而终止性则是确保系统能够持续运行和更新，避免因无法做出决策而陷入停滞。通常，我们将满足一致性和正确性的特性称为安全性（Safety），而满足可结束性的特性称为活性（Liveness）。这两个属性是评价一个分布式系统共识算法效能的关键指标。

### 5. 通信模型

在分布式系统中，有效的通信是系统性能和可靠性的关键因素。通信模型定义了消息传递的时效性及其对系统的限制。基本上，可以将通信模型分为三种类型：同步、异步和部分同步。

#### 5.1 同步模型

在同步通信模型中，所有节点间的通信延迟有一个预定义的上限。如果通信超过了这个上限，相关节点将被视为发生故障。这种模型提供了一种非常理想的环境，使得早期的分布式一致性算法能在较为简单和明确的条件下进行设计。同步模型假定了网络的可预测性，这在实际应用中往往难以实现，但它便于算法的理论分析和初步实现。

#### 5.2 异步模型

相比之下，异步通信模型不设定任何关于通信延迟的上限。在这个模型中，消息可能在任何未知的时间到达，或因为各种原因（如网络延迟、硬件故障等）延迟未到。这种模型更加贴近现实世界中的网络环境，因此在设计上更具挑战性和实用性。在异步模型中有效的共识算法，由于其健壮性，也必然适用于同步模型，但是同步模型下的算法不一定能够适应异步模型的不确定性。

> 在异步模型中设计一个完美的共识算法被证明是**不可能**的！

#### 5.3 部分同步模型

部分同步模型介于同步和异步之间，提供了一个更加灵活的框架。在这个模型中，系统可能在大部分时间内表现为异步，但偶尔会有同步的行为。这种模型尝试在理想的同步假设和现实的异步条件之间找到平衡，是很多现代分布式系统设计中的首选模型。

总体来说，选择哪种通信模型将直接影响共识算法的设计和系统的整体可靠性。每种模型都有其优势和局限性，理解这些差异对于开发和维护大规模分布式系统至关重要。

### 6. FLP 定理

1985 年，Fischer、Lynch 和 Patterson 三位科学家发表了论文，提出了著名的 FLP 定理，它是分布式系统领域的最重要定理之一。该定理给出了一个重要的结论：

> FLP 定理：在一个异步通信网络中，只要存在一个故障节点，就不存在一种完美的共识算法可以正确地终止（使所有节点达成一致）。

FLP 定理在理论计算机科学中是一个关键的结果，它揭示了在某种假设条件下共识算法面临的基本限制。这个定理是在一个比异步通信更理想的模型下得出的，该模型假设系统中不存在拜占庭错误，并且所有消息最终都会成功传递，不会丢失或重复。尽管这种通信模型比现实中的网络环境更为理想和可靠，FLP 定理却表明，即便在这样的环境下，如果允许任意时间停止某个节点或进程，那么无法保证所有共识算法都能达到终止性，即最终一致性。

这一结果的意义在于，它说明了在现实中更加复杂和不可靠的异步网络中，达成一致性的挑战更大。在这种背景下，现实网络中不仅可能遇到消息延迟，还可能面对网络分区（系统中部分节点网络不通，导致系统被划分为不同区域）和拜占庭错误等问题。

因此，为了实现实用的共识算法，设计者通常需要在模型假设上做出一定的妥协。例如，许多现代共识算法不再采用纯异步模型，而是选择部分同步模型，该模型允许系统在一定时间内处于异步状态，不要求立即达成共识，但预期网络最终会恢复到同步状态，届时可以迅速达成共识。这种方法虽然对系统的活性（即系统继续运行和做出决策的能力）有所影响，但只要能够在关键时刻保证系统的安全性，这种妥协仍是可接受的。

例如，Paxos 算法理论上可能出现活锁，即算法在特定情况下可能无法前进，但它保证了即使在活锁状态下，系统的状态是安全的。在实际应用中，一旦活锁问题被解决，系统就可以恢复正常，继续推进共识进程。这样的设计思路显示了在理论限制和实际应用之间寻找平衡的重要性。

> FLP 定理在论文中有其完整证明过程，非数学专业不易看懂，感兴趣者请自行查阅资料。

在设计共识算法时，考虑到现实中的技术和环境限制，各种算法通常需要在以下几个关键假设之间做出选择：

1. 故障模型:

   - 非拜占庭故障：假设故障仅限于节点宕机或失去响应，不包括恶意行为。
   - 拜占庭故障：假设包括节点可能出现的恶意行为，如数据篡改、发送虚假信息等。
2. 通信类型:

   - 同步：假设存在一个已知的最大通信延迟，超过该延迟的通信被认为是节点故障。
   - 异步：没有固定的通信延迟界限，消息可能在任何未知时间到达。
3. 通信网络连接:

   - 节点间的连接数，直接影响到信息的传播速度和网络的弹性。
4. 信息发送者身份:

   - 实名：参与节点的身份是公开和可验证的。
   - 匿名：参与节点可以隐藏自己的真实身份，增加了设计的复杂性和安全性。
5. 通信通道稳定性:

   - 可靠：通信通道稳定，消息传输可靠，不会丢失。
   - 不可靠：通信可能会丢失、受损或被篡改。
6. 消息认证性:

   - 认证消息：消息包含机制以确保内容的真实性，如数字签名。
   - 非认证消息：消息不包含额外的验证信息，接收方无法验证消息的真实性。

这些假设在共识算法的设计中起着决定性作用，不仅影响算法的复杂度和实现方式，还决定了算法能在哪种网络环境中有效运行。通过在这些假设中找到适当的平衡，可以设计出既安全又高效的共识算法。

### 7. CAP 定理

在 2000 年的 ACM PODC 会议上，加州大学伯克利分校的 Eric Brewer 教授首次提出了 CAP 猜想，这一猜想后来由 MIT 的 Seth Gilbert 和 Nancy Lynch 在 2002 年从理论上证明，因此成为了分布式计算领域公认的 CAP 定理。该定理阐述了在设计分布式系统时面临的关键权衡：一个系统不可能同时满足以下三个属性：

- 强一致性（Consistency）：确保所有节点在完成写操作后能返回最新的数据。若不是最新的数据，则返回错误。这种级别的一致性要求非常高，实际应用中往往采用更灵活、成本更低的一致性模型，如最终一致性。
- 可用性（Availability）：系统必须确保对客户端的每个请求都能在一定时间内给予响应，无论请求的结果如何，保证服务的持续可用。
- 分区容错性（Partition tolerance）：即使出现网络分区，部分节点之间失去通信，系统仍需能继续运行。

CAP 定理的核心观点是，在分布式系统的设计中，不可能同时完全实现这三个目标。因此，设计者需要根据系统的具体需求和环境条件作出选择和取舍。例如，由于网络分区在分布式环境中几乎是不可避免的，系统设计通常会围绕如何在一致性和可用性之间做出平衡。AWS 的 Dynamo 数据库选择了优先保证可用性而牺牲一部分一致性；相对地，谷歌的文件系统 GFS 则在某种程度上牺牲了可用性，以提高数据的一致性。这些设计选择反映了 CAP 定理对现代分布式系统架构的深远影响。

## 二、共识算法分类

共识算法作为区块链技术的核心组成部分，已经经历了四十年的发展历程。从最初的传统分布式一致性算法到如今区块链领域内多样化的共识算法，每种算法都有其特定的侧重点和适用环境。以下是从几个关键角度对共识算法进行的分类：

**容错类型**

共识算法按照其解决拜占庭错误的能力可以分为两类：

1. 拜占庭容错共识算法：包括 PBFT、PoW（工作量证明）、PoS（权益证明）、DPoS（委托权益证明）等。这类算法能够在节点可能存在恶意行为的环境中维持网络的一致性和安全。
2. 非拜占庭容错共识算法：如 Paxos、Raft 等。这些算法假设节点基本诚实，主要解决的是因网络故障或节点失效导致的问题。

在公链环境中，通常采用拜占庭容错算法，以抵御潜在的恶意攻击；而在联盟链中，则可以根据参与方之间的信任程度选择合适的算法。

**算法确定性**

共识算法按照其决策的确定性可以分为：

1. 确定性共识算法：如 Paxos、Raft、PBFT 等。这些算法一旦达成共识，其决策就是最终的，不存在回退的可能性。
2. 概率性共识算法：如 PoW、部分 PoS 等。这类算法达成的共识可能会在未来某个时间点被回退，但这种概率随时间延长逐渐趋近于零。

确定性共识算法通常用于需要高可靠性的系统，而概率性共识算法则常见于公链环境，其中对安全性和去中心化有更高的要求。

**选主策略**

共识算法在节点如何成为出块节点这一决策上也有所不同：

1. 选举类共识算法：如 Raft、PBFT。这些算法通过节点间的投票机制来选举出块节点，选举出的节点可以在多轮中连续作为出块节点。
2. 证明类共识算法：如 PoW、PoS。这些算法要求节点通过展示其计算能力或持有的货币量等方式来赢得出块的权利，通常每轮选举的出块节点都是不同的，以增强系统的公平性和安全性。

每种共识算法的选择不仅反映了技术和安全需求，还涉及到政治和经济因素，尤其是在公链如比特币或以太坊这类去中心化网络中。这些算法的设计和选择，显著影响了区块链系统的性能、安全性、以及用户的信任度。

## 三、传统分布式一致性算法

在区块链和其他分布式系统中，确保节点间一致性是关键挑战之一。存在一类特定的算法，通常被称为**非拜占庭容错共识算法**，这些算法不处理拜占庭错误（即节点的恶意行为），而是专注于解决节点可能的宕机或网络故障问题。这类算法广泛应用于需要高度一致性保障的系统，如数据库。

以下是一些著名的分布式一致性算法，它们在各种技术环境中确保数据一致性：

- 2PC（两阶段提交）
- 3PC（三阶段提交）
- Paxos
- ViewStamp Replication
- Zab
- Raft

这些算法各有其应用场景和优势。例如，2PC 和 3PC 广泛用于事务性数据库环境，确保事务在多个数据库副本之间正确提交或回滚。接下来，我们将深入探讨 Paxos 算法，这是一种高度关注在节点可能出现故障时如何维持系统一致性的算法。

### 1. Paxos

Paxos 是一种在异步模型下设计的共识算法，它能够保证系统的正确性和容错性。根据 FLP 定理，在纯异步系统中，只要存在节点故障，就不可能实现一个始终可终止的共识算法。因此，Paxos 算法在设计上做了权衡，牺牲了部分活性（Liveness），即在系统完全异步的状态下允许暂停共识过程，以确保系统的安全性（Safety）。这意味着只要系统中超过半数的节点能恢复到同步状态，Paxos 便能继续推动共识过程，实现决策的终结。

**Paxos 算法的关键特性：**

- 安全性：Paxos 确保所有非故障节点都会达成一致的决策，且这些决策必须由参与的节点中的某些节点提出，确保了系统的一致性。
- 无保证的终止性：虽然 Paxos 设计目的是最终达成一致，但在某些极端的异步条件下，可能不会达到最终决策的状态。这不保证算法在所有情况下都能迅速收敛至一个共识结果。
- 容错性：Paxos 可以容忍少于半数的节点出现宕机或故障。在这种情况下，剩余的健康节点仍然有能力达成共识，保持系统的运行。

Paxos 算法通过这些特性提供了一个强大的框架来处理分布式系统中的一致性问题，特别是在网络条件不稳定或节点可能不可靠的环境中。这种设计使得 Paxos 在理论和实践中都非常有价值，尽管它的复杂性有时会使实现和理解变得具有挑战性。

Paxos 算法，虽然最初被视为理论上的解决方案，随后却衍生出多个实用的变体，这些变体已被广泛应用于各种实际的系统中。Paxos 家族包括 Basic Paxos、Multi Paxos、Cheap Paxos、Fast Paxos 等一系列协议。每种变体针对不同的系统需求和性能考量进行了优化。

- Basic Paxos 主要处理单一决策值的一致性问题。
- Multi Paxos 扩展到连续的多值决策，提高了处理连续事务的效率。
- Raft 是基于 Multi Paxos 思想的变体，以其易理解性和易实现性而受到青睐。

**Basic Paxos 大致流程**

**角色定义**

- Proposer（提议者）：负责发起提案，希望被选为领导者（Leader）。Proposer 将提议值广播给 Acceptor，并收集他们的投票以决定最终的提议值。系统中可以同时存在多个 Proposer。
- Acceptor（接受者）：接收 Proposer 的提议值，并根据特定规则决定是否接受这个提议。
- Learner（学习者）：不直接参与投票，但需要知晓并遵循最终被选定的提议值。
- Leader（领导者）：从众多 Proposer 中选出的领导者，其提议值被系统其他成员遵守。

**初始设置**

每个参与节点需初始化以下几个关键值：

1. N<sub>a</sub>，V<sub>a</sub>：该节点接受的最大提案号及相应的提议值。
2. N<sub>h</sub>：该节点响应过的最大提案号。
3. MY<sub>n</sub>：该节点在当前共识轮中提出的提案号。

**阶段一：准备阶段**

在 Paxos 算法的准备阶段，流程开始于一个或多个节点的提议发起：

1. 提议发起：

   - 当一个节点（称为 Proposer）决定发起一个新的提案，它首先需要选择一个唯一的提案编号 MY<sub>n</sub>，确保此编号大于该节点之前响应过的任何提案编号 N<sub>h</sub>。
   - 接着，Proposer 向集群中的多数节点发送 Prepare 请求，请求格式为 Prepare(N)，其中 N 代表提案编号 MY<sub>n</sub>。
2. Acceptor 的响应：

   - 每个收到 Prepare 请求的节点（称为 Acceptor）首先检查请求中的提案编号 N。
   - 如果提案编号 N 小于或等于该 Acceptor 已经响应过的最大提案编号 N<sub>h</sub>（N ≤ N<sub>h</sub>），Acceptor 将向 Proposer 发送 Reject 消息，拒绝该提案。
   - 如果提案编号 N 大于 Acceptor 响应过的任何提案编号（N > N<sub>h</sub>），Acceptor 将执行以下操作：
     - 发送一个承诺消息 Promise(N<sub>a</sub>, V<sub>a</sub>)给 Proposer，其中 N<sub>a</sub>是该 Acceptor 之前接受的最大提案编号，V<sub>a</sub>是与 N<sub>a</sub>相关联的提议值。
     - 更新其内部记录的 N<sub>h</sub>至 N，表示承诺不再接受任何编号小于 N 的提案。
     - 如果该 Acceptor 从未接受过任何提案，它将发送 Promise(Null, Null)消息，表示其承诺是基于没有先前承诺的状态。

通过这种方式，Paxos 算法的准备阶段确保所有的 Acceptor 都对即将进行的提议投票过程有共同的理解，并为 Proposer 提供了关于集群当前状态的重要信息，从而支持其决策过程。这个阶段是建立共识过程中信任和一致性的基础。

**阶段二：接受阶段**

接受阶段是 Paxos 算法中的关键部分，涉及到提案的最终接受与否。这一阶段的目的是让提案获得足够的支持，从而确立一个共识值。以下是详细步骤：

1. 评估响应：

   - 如果 Proposer 从超过半数的节点收到了对其 Prepare(N)请求的正面响应，它将继续评估这些响应。
   - 从接收到的 Promise 消息中，Proposer 找出具有最大提案号的响应（Promise(N<sub>n</sub>, V<sub>n</sub>)），并选择与之相关的提议值 V<sub>n</sub>作为共识提议。
   - 如果所有响应中的提议值均为 Null，表明没有有效的先前提议，Proposer 则可选择一个新的提议值 V，并发起 Accept(N, V)请求。
   - 如果接收到任何 Reject 消息，这表明存在一个更高编号的提案已被提出。在这种情况下，Proposer 需回到阶段一重新发起新的 Prepare 请求，使用更高的提案号。
2. 处理 Accept 请求：

   - 当 Acceptor 收到 Accept(N, V)请求时，它将检查请求中的 N 与本地记录的最大响应编号 N<sub>h</sub>。
   - 如果 N 大于 N<sub>h</sub>，表明这个 Accept 请求有效，Acceptor 则同意这个请求，发送 Agree 响应给 Proposer，并更新本地的 N<sub>h</sub>和 N<sub>a</sub>为 N，V<sub>a</sub>为 V，表明已接受该提议。
   - 如果 N 小于或等于 N<sub>h</sub>，则 Acceptor 将拒绝这个请求并发送 Reject 消息给 Proposer，因为根据协议规则，Acceptor 不能接受编号小于或等于之前承诺过的提案号的提议。

这个阶段是确保提议得到足够多的接受并防止老旧提议干扰新的共识过程的关键。成功的话，这将为系统中的节点建立一个新的、被大多数节点接受的共识值，从而维护系统的整体一致性和稳定性。

**活锁问题**

在 Paxos 算法的接受阶段，一个常见的问题是活锁。活锁发生时，多个 Proposer 可能因为互相覆盖对方的提案（通过提出更高编号的提案）而导致系统无法进入稳定的共识状态。这主要是因为当 Proposer 收到 Reject 响应后，会重新发起带有更高提案号的 Prepare 请求，从而触发新一轮的共识尝试。如果多个 Proposer 并行工作，这种情况可以不断重复，从而使系统陷入一个循环，无法达到最终共识。

**解决活锁的策略包括：**

1. 固定 Proposer 选举：

   - 通过选择一个固定的 Proposer，可以减少提案号的竞争和相互覆盖，从而降低活锁的发生率。在这种设置中，只有一个选定的 Proposer 负责发起提案，其他节点则作为 Acceptor 参与共识过程。
2. 设置超时和随机化机制：

   - 给不同的 Proposer 设置不同的超时时间或随机化提案号的生成策略可以有效地减少同时发起提案的概率。通过这种方式，可以减少 Proposer 之间的直接竞争，允许系统有更多的机会达成一致。
   - 这种方法在异步网络环境中尤其有用，因为即使在网络延迟或其他不确定因素的影响下，这种随机化和超时设置也可以帮助避免提案的直接冲突。

尽管这些策略可以减轻活锁问题，但在纯异步网络中完全避免活锁仍是一个挑战。网络的不确定性和节点间的非同步交互可能导致系统需要额外的机制或更复杂的设计来应对这种状态。因此，设计一个高效且可靠的共识机制不仅需要考虑如何达成共识，还要考虑如何处理共识过程中可能遇到的各种异常情况。

**无法逃脱 FLP 定理**

FLP 定理揭示了在纯异步通信模型中，如果系统中存在节点故障，那么不可能保证所有的共识算法都能达到完全的终止性。这意味着在一些情况下，系统可能无法达成最终共识。Paxos 算法在面对这种理论限制时采取了一种平衡方法，尽管它不能完全克服 FLP 定理的限制，但通过一些设计选择，它尽可能地维护了系统的功能。

在系统运行于异步状态——比如因为网络故障或节点失效导致节点间无法有效通信时——以下是 Paxos 算法的响应机制：

1. 保证安全性（Safety）：

   - 当 Proposer 能从过半数的 Acceptor 接收到响应时，Paxos 确保这些响应是基于最新的、有效的共识尝试。这样即使在异步环境下，只要足够多的节点能响应，系统仍能保持一致性并达成共识。
   - 这种设计确保了任何已达成的共识都是正确的，即所有非故障节点在任何时候都同意同一个决策。
2. 活性（Liveness）的牺牲：

   - 如果 Proposer 无法从过半数的 Acceptor 获得响应，Paxos 不保证共识能立即完成。这种情况下，共识过程可能会进入停滞状态，直到网络通信恢复并且足够多的节点能够再次参与投票。
   - 这种停滞不是永久性的；一旦条件允许，共识过程可以恢复并最终达成。这种设计虽牺牲了一部分活性，但是在不稳定的网络环境中，它提供了对安全性的强保证。

Paxos 算法的这种处理方式，即在异步网络中牺牲部分活性以确保系统安全性，展示了在现实世界应用中如何接受理论限制并优化算法设计。这种权衡在设计需要高度可靠性的分布式系统时尤其重要，因为在这些系统中，维持数据的一致性和正确性是至关重要的。

**Paxos 优点**

Paxos 算法拥有多个显著优点，使其在分布式系统中作为一种可靠的共识机制得到广泛应用：

- **平等的共识机制**：Paxos 不设立任何节点为特权节点，确保了系统的民主性。在这个框架中，每个节点都有权发起提案，这消除了对任何单个节点的依赖，增强了系统的去中心化特性和鲁棒性。
- **有序的提案机制**：Paxos 通过独特的提案编号系统来排序提案，即使在多个 Proposer 同时提出不同的提案值时，也能通过这一机制确保所有提案最终能够收敛至一个共识值。这种排序确保了提案处理的一致性和系统状态的最终一致性。
- **多数派共识**：Paxos 算法的另一个关键优势是其对多数派的依赖，它不要求每一轮共识都必须获得所有节点的参与。只要超过半数的节点参与投票，共识即可推进。这种设计不仅提高了算法的效率，也增强了对故障的容忍能力。在实际应用中，即使面临网络分区等问题，Paxos 仍能保持系统的操作性和安全性，只要多数节点仍能正常通信。

这些特性使得 Paxos 算法在处理分布式系统中的一致性问题时，能够提供一个既安全又高效的解决方案，尤其适用于环境条件复杂且对一致性要求极高的场景。

**Paxos 缺点**

虽然 Paxos 算法为分布式系统中的一致性问题提供了有效的解决方案，它在处理异步网络环境下的一致性挑战时展示了强大的能力，但 Paxos 也具有一些显著的缺点：

- **复杂性**：Paxos 算法的理论基础和实现细节相对复杂，难以理解和部署。这种晦涩难懂的性质使得它在实际应用中可能遇到实施难题，特别是对于非专业的开发人员。
- **实用性挑战**：在实际操作中，Paxos 的复杂性可能导致实现上的错误和效率问题。因此，许多后续的共识算法设计都基于 Paxos 的核心理念进行简化和优化，以提高算法的可理解性和可操作性。
- **二次设计**：由于原始 Paxos 算法的这些限制，产生了多种基于 Paxos 原理的改良算法，旨在提供更为简洁和高效的解决方案。这些算法如 Raft、Chubby、Zookeeper 和 etcd，不仅继承了 Paxos 的核心优势，还各自增加了易于理解和实施的特性，使其在特定应用场景，如联盟链和私链中，得到了广泛的应用。

接下来的部分将重点介绍 Raft 算法，探讨其如何在保持 Paxos 核心优点的同时，提高了算法的易用性和可靠性，尤其是在联盟链和私链的应用中。

### 2. Raft

尽管 Paxos 算法对分布式一致性算法的发展产生了深远影响，并且奠定了理论基础，但由于其复杂性和难以理解的特性，它在实际应用中经历了一段较长时间的沉寂。直到 Chandra、Griesemer 和 Redstone 在 Chubby 中实施了 Paxos，这种分布式锁服务的实现使得 Paxos 开始广为人知并逐渐声名鹊起。即便如此，实现一个完整的 Paxos 系统仍然非常具有挑战性，这促使了多种 Paxos 变体的诞生，其中最为人熟知的是 Raft 算法。

Raft 是一种专门用于管理日志复制的一致性算法，旨在为真实世界的应用提供一个既可靠又易于理解的协议。它继承了 Paxos 的容错性和性能优势，但不同之处在于 Raft 将一致性问题划分为三个较为独立的子问题：领导选举、日志复制和安全性。这种结构化的方法不仅简化了问题，也增强了算法的可实施性和可理解性。在区块链技术中，Raft 算法也被用来处理记账共识，展示了其广泛的适用性和实用价值。

#### 2.1 Raft 基础概念

Raft 是一种共识算法，设计用于管理分布式系统中的日志复制，通过明确划分系统角色和任期管理简化了共识过程。在 Raft 中，节点根据其职责可以分为三种角色：

- **Leader：** Leader 负责处理所有客户端请求。如果 Follower 节点接收到客户端的请求，它会将请求转发给 Leader。当存在一个 Leader 时，系统中不会有 Candidate 节点。
- **Candidate：** Candidate 是在选举 Leader 阶段出现的临时状态。任何节点在检测到现有 Leader 故障或任期结束时可以成为 Candidate。
- **Follower：** 这是节点的默认初始状态。Followers 处于被动接收状态，不会主动发起请求。如果在选举期间 Follower 没有收到来自 Leader 的心跳信号，它将转变为 Candidate 状态，并参与 Leader 的竞选。

在 Raft 协议中，时间被划分为若干个“任期”（term），每个任期由一个独特的连续编号标识。每个任期开始时都会进行一次选举，如果某个 Candidate 赢得了多数票，则它将在该任期剩余时间内担任 Leader。如果选举结果未能明确产生一位 Leader，则系统将立刻进入下一个任期并重新进行选举。这种机制确保了系统的一致性和高可用性，同时也易于理解和实现，使得 Raft 成为处理分布式系统一致性问题的流行选择。

#### 2.2 过程详解

**阶段一：Leader 选举**

在 Raft 协议中，所有节点初始状态为 Follower。Follower 角色的节点会保持监听状态，接收来自 Leader 或 Candidate 的消息。Leader 负责维护自己的领导地位，通过向所有 Follower 定期发送心跳消息来实现。如果一个 Follower 在设定的周期（通常是 150~300 毫秒）内未收到心跳，它便会认为当前无有效的 Leader，并启动选举流程，自我提升为 Candidate。

选举过程中的具体步骤包括：

1. 启动选举：

   - Follower 首先增加自己的任期号，然后变更其状态为 Candidate。
   - 该 Candidate 为自己投票，并向其他节点发送 RequestVote 请求以寻求支持。
2. 选举结果：

   - 如果 Candidate 在当前任期内获得了超过半数节点的投票，它则胜出，成为新的 Leader。
   - 作为 Leader，它将开始定期向所有节点发送心跳消息，确认自己的领导地位并阻断可能的新选举。
3. 接收到心跳：

   - 在等待投票结果期间，Candidate 可能会收到新 Leader 的心跳消息。
   - 如果心跳消息中的任期号大于 Candidate 当前的任期号，Candidate 将承认新 Leader 的合法性并转变回 Follower 状态。
   - 如果心跳任期号不大于自己的任期号，Candidate 将继续保持 Candidate 状态并等待选举结果。
4. 选举超时：

   - 如果在一定时间内没有 Candidate 赢得选举，通常是因为多个 Candidate 同时竞争导致票数分散。
   - 此时，每个 Candidate 将在随机延时后再次发起选举，延时时间设置在 150~300 毫秒内，目的是减少同时触发的可能性，从而提高成功选举的几率。

通过这种机制，Raft 算法确保了系统在 Leader 失效时能迅速而有效地重新选举出新的 Leader，同时避免了长时间的领导空缺和选举冲突，增强了系统的稳定性和可靠性。

**阶段二：日志复制（对应区块链中的记账过程）**

一旦 Leader 被选出，它便开始处理来自客户端的请求。每个请求包含一条命令，这条命令需要通过状态机来执行。Leader 首先将命令添加到自己的日志中作为新的日志条目。随后，Leader 向其他 Follower 节点广播 AppendEntries 请求，这一请求包含日志条目的内容，要求 Follower 节点复制该日志条目。

当日志条目在所有节点上成功复制后，Leader 将其应用到自己的状态机，并向客户端反馈执行结果。如果在一定时间内 Follower 没有响应（可能由于崩溃、执行延迟或网络问题），Leader 将持续重发 AppendEntries 请求，直到所有 Follower 成功存储该日志条目为止。

一旦日志条目被大多数节点复制，该条目便达到了可提交的状态（Committed）。此时，Leader 记录下这个条目在日志中的最高序号，并在后续的 AppendEntries 请求（包括心跳消息）中包含这个序号，以通知其他节点该日志条目已经被提交。Follower 收到这个信息后，会将日志条目应用到自己的本地状态机中执行。

这个过程不仅确保了数据的一致性和完整性，还提高了系统的可靠性和效率，使得 Raft 算法特别适合处理区块链等需要高可靠性记账处理的分布式系统。

**阶段三：Leader 失联**

在日志复制阶段（阶段二），如果出现网络故障或网络分区事件，可能导致现任 Leader 无法与大多数 Follower 保持联系。在这种情况下，那些失去与 Leader 联系的 Follower 将触发新一轮的领导选举。

当网络问题解决并且连接恢复后，系统将依据 Raft 算法中定义的任期号规则来处理。具体来说，如果在 Leader 失联期间已经选出了新的 Leader，旧 Leader 在重新连接后将自动降级为 Follower。此外，旧 Leader 在失联期间所做的任何更新将被认为无效并需进行回滚，以确保系统状态的一致性。

随后，旧 Leader 将接受新 Leader 的指令，并更新其日志和状态机以匹配集群的当前状态。这个机制确保了即使在 Leader 暂时失联的情况下，整个系统也能保持运行和数据一致性，强化了 Raft 算法在处理网络问题和节点故障时的健壮性。

### 3. 传统分布式一致性算法小结

传统分布式一致性算法，特别是基于 Paxos 的共识协议，已经在许多分布式系统中得到广泛应用。这些系统包括但不限于 Chubby、Zookeeper 和 etcd 等，每个都在不同的环境中扮演关键角色。

- Chubby：谷歌的 GFS（Google File System）和 BigTable 等关键系统采用了 Chubby 的分布式锁协议来管理资源和状态的一致性，确保了这些系统的高可用性和数据一致性。
- Zookeeper：由 Yahoo 公司开发，已成为 Hadoop、OpenStack 和 Mesos 等分布式系统的标准部分。Zookeeper 提供可靠的分布式协调服务，通过维护配置信息、命名、同步以及提供组服务来简化这些系统的集群管理。
- etcd：是由 CoreOS 团队开发的，现在已成为 Kubernetes 的核心组件之一，主要用于保存和正确同步所有集群数据，确保集群状态一致。

尽管这些协议在传统的分布式系统中应用广泛，但在区块链技术场景中的出现相对较少。超级账本 Fabric 1.0 是一个例外，它采用了基于 Zookeeper 的 Kafka 作为排序引擎，显示了这些传统协议在新兴区块链技术中的潜在应用。

总体来看，这些基于 Paxos 的共识协议由于其强大的一致性保证和系统设计的灵活性，在分布式系统的构建中扮演了不可或缺的角色。它们为处理大规模系统中的一致性问题提供了有效的解决方案，尽管在区块链领域它们的应用仍在探索阶段。

## 四、区块链共识算法

传统分布式一致性算法只能运行在不存在拜占庭节点的场景中，如数据库备份、日志备份、分布式锁等。但是在区块链（公链）系统中，没有对节点加入做鉴权，所以

利益的驱使下一定会存在恶意节点，因此在选择区块链共识算法的时候，必然要考虑节点作恶的情况，如双花攻击、51% 算力攻击等。在进行区块链共识算法选择时，通常

根据两种思路选择：

1. 公链项目，考虑节点规模和安全性。通常选择能够容忍拜占庭故障的共识算法，如 PoW、Pos、DPoS 等；
2. 联盟链和私链项目，更考虑高性能和低延迟。通常选择经典 PBFT、Raft 等。

在公链项目中，因为存在拜占庭节点和节点规模较大的问题，只能采用最终一致性的共识算法，没法采用强一致性算法（如 Raft）。在联盟链和私链项目中，

通常对共识算法有强一致性和高性能需求，而且一般来说也不会出现拜占庭故障（节点加入要接受鉴权）。因此，在这个场景下可以考虑采用传统分布式一致性算法（非拜占庭容错共识算法）。

在 Hyperledger 的 Fabric 项目中，共识模块是被设计为可插拔的，支持 PBFT、Raft 等算法。目前在区块链项目中，比较常见的非拜占庭容错共识算法是 Raft。

### 1. PoW 共识算法

最早在 1993 年由 Cynthia Dwork 与 Moni Naor 在学术论文中提及，并于同年由 Markus Jakobsson 与 Ari Juels 正式提出。起初，PoW 主要是用于防止垃圾邮件的产生，2008 年，PoW 作为共识算法应用在比特币系统中。
比特币系统的一个重要概念是基于互联网的去中心化分布式账本，该账本以区块链形式保存，每个账本相当于账本页，区块中的信息主体就是交易内容。但是在去中心化系统中由谁来负责记账，这是一个难点，因为不可能允许每个节点都能同时记账，这会导致账本的不一致。因此需要达成由哪个节点获得记账权的共识。PoW 算法就是通过基于算力的随机性竞争记账的方式，来选出一个记账节点打包区块，然后向其他节点广播这个新增区块信息。从此解决去中心化系统中的记账一致性问题。
那么如何比拼算力？具体来说就是一份确认工作量的证明。节点需要消耗一定算力去计算以完成工作得出结果，然后交给验证方进行验证，验证工作是可以很快的。
举个例子，对于给定的一个字符串「blockchain」，给出的工作量要求是，可以在这个字符串拼接一个成为 Nonce 的整数字符串，然后对拼接后的整个字符串进行Sha-256 哈希运算，如果得到的哈希结果（十六进制）是以若干个 0 开头的，则验证通过。为了达到这个目标，需要不停的枚举 Nonce 值（一般来说是递增），没有任何技巧，然后对得到的字符串进行哈希运算。按照这个方式，需要经过 2688 次才能找到前三位均为 0 的哈希值；而要找到前六位均为 0 的哈希值，则需要进行约 62 万次计算。

上面的例子就是比特币中 PoW 的大致逻辑。其中，主要有三个要素：

- 工作量证明函数：不断枚举 Nonce 并哈希的过程，PoW 使用的哈希函数就是 Sha-256
- 区块：这道题的输入数据，代替上述字符串「blockchain」；区块由区块头和区块体组成。区块头为 80B，包含 4B 的版本号、32B 的上个区块的哈希值、32B 的

默克尔根哈希值、4B 的时间戳（当前时间）、4B 的当前难度值（实际存的是难度值转换后的目标哈希值,通常表示为 nBits）、4B 的随机数组成。区块体就是交易列表，其中第一笔交易是 CoinBase。

- 难度值：是比特币节点生成区块时的重要参考指标，它决定了节点大约需要经过多少次哈希运算才能产生一个合法区块。

#### 1.1 区块结构（多图说明，图源自互联网）

![](static/DPd8b3aiUoKfayxOy0EcO7bSnCe.png)

![](static/VyvUbkDvTojJAnxocdQcZ5j7n1g.png)

![](static/MPcjbyEpdovxRyx3NTXcjuPpnAc.png)

```
// 区块头结构：80字节
struct header_structure {      // BYTES   NAME
 uint32_t nVersion;            // 4       version
 uint8_t hashPrevBlock[32];    // 32      previous block header hash
 uint8_t hashMerkleRoot[32];   // 32      merkle root hash
 uint32_t nTime;               // 4       time
 uint32_t nBits;               // 4       target
 uint32_t nNonce;              // 4       nonce
};
```

#### 1.2 难度值

比特币的区块大约每 10 分钟生成一个，如果要在全网算力持续变化的过程中，让新区块产生速率保持不变的话，难度值就需要根据全网算力进行不断调整。

难度调整是在每个全节点中独立自动发生的。每 2016 个区块，所有节点都会按统一公式自动调整难度，这个公式是由前 2016 个区块的花费时长和期望时长比较得出的。

> 期望时长是 20160 分钟，即两周，是按每 10 分钟产生一个区块的速率计算得来的。

如果前 2016 个区块的花费时长比期望时长更短，则增加难度，否则减小难度。大致计算公式：

> 公式 1：新的难度目标值 = 旧的难度目标值 * 生成最近 2016 个区块所花费的实际时间 / 系统期望生成 2016 个区块的时间

注意，这个难度目标值越大，则难度越小，是反比，下面会说明目标值和难度的换算关系。

在比特币区块头中，难度值是一个 32B(256b)的数被压缩成一个 4B 的难度位 nBits 存储，所以区块头中存的

难度值实际是难度值转换后的目标哈希值，目标值的大小与难度值成反比，转换公式：

> 公式 2：目标哈希值(current_target)=最大目标值(difficulty_1_target) / 难度值(difficulty)

其中最大目标值是一个 32 字节恒定值，是比特币创世区块的 target 哈希值，比特币工作量证明的达成就是矿工计算出的区块哈希值必须小于目标哈希值。

**难度值表示：nBits、Target Threshold 和 Difficulty**

如果读者对比特币挖矿难度值有过研究，就会发现不同的资料/图片会使用这三个字段中的一个来表示难度值，上面的图片就是例子。下面进行这三个字段的详细解释。

**【nBits & Target Threshold】**

在区块头中直接存储的是 nBits 这个字段，占用 4 字节。nBits 是一个无符号的 32 位整数，它是将 32 字节的 **Target Threshold** 根据一个固定算法压缩得来，目的是节省空间。

而 **Target Threshold** 就是某一个区块头的最大哈希值，矿工多次计算得出的区块哈希只要小于等于它就说明打包的区块是一个有效的区块，就可以广播全网，

从而获得比特币奖励。

Target Threshold 压缩算法： nBits 的最高位的 1 个字节代表指数（exponent），低位的 3 个字节代表系数（coefficient）， 这个记法将工作量证明的 target 表示为系数/指数(coefficient/exponent)的格式。

计算难度目标 target 的公式为：target = coefficient * 256^(exponent – 3)，以区块[#277,316](https://www.blockchain.com/explorer/blocks/btc/0000000000000001b6b9a13b095e96db41c4a928b97ef2d944a9b31b2cc7bdc4)

为例，nBits=0x1903a30c（十进制为 419668748），则有 0x19 为幂（exponent ），而 0x03a30c 为系数（coefficient），所以这个区块的 target 值为：

```
target  = 0x03a30c * 256^(0x19 - 3)
        = 238,348 * 256^22
        = 22,829,202,948,393,929,850,749,706,076,701,368,331,072,452,018,388,575,715,328
```

十六进制为 `0x0000000000000003a30c00000000000000000000000000000000000000000000`,也就是说高度为 277316 的有效区块头的哈希值，要小于等于这个目标值。

而高度 277136 区块的 Hash 值实际为 `0x0000000000000001b6b9a13b095e96db41c4a928b97ef2d944a9b31b2cc7bdc4`（在上述区块链接中可查）。

**【Difficulty：难度值】**

Difficulty 的定义是为了使区块头的 SHA256 结果小于某个目标值（target），平均要尝试的计算次数。显然，随着矿机节点的不断加入，全网算力会不断增加，而为了使

出块时间保持在 10 分钟每块的速度，就必须增加 Difficulty。通过查询比特币的[创世区块](https://www.blockchain.com/explorer/blocks/btc/000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f) ，

可以得知创世区块的 Bits 为 486,604,799（十六进制为 0x1d00ffff），此时它的 Difficulty=1。根据 Bits，算出 target 为 0x00ffff * 256^26，即 `0x00000000ffff0000000000000000000000000000000000000000000000000000`，

说明有效哈希值必须小于等于它，而通过观察，要小于等于它，其实就是要求计算出的哈希值前 32 位必须是 0，因为 sha-256 的计算结果被认为是随机的，可以说，SHA256 的结果中的某一位的值，为 0 或为 1 的概率相同。

所以做一次计算，满足上述条件（前 32 位的值均为 0）的概率为 1 / (2^32)，也就是平均要做 2^32 次运算，才能找到这个值。

也就是说，1 Difficulty ≈ 2^32 次计算，那么这里就会有一个全网算力和全网难度的关系公式：

> 当前出块时间（约 10min）= 当前全网难度(Difficulty) * 2^32 / 当前全网算力(Hash rate)

下面简要描述一下出块时间的计算过程：

```
出块时间(单位：秒) ≈ difficulty_当前 * 2^32 / 当前全网算力
全网算力：全网比特币矿机算力总合
比如，网络中现在有1亿台比特币的挖矿机器，每台算力是10t，那么全网算力就是10亿T，换算一下单位就是100E算力即100Ehash/s，表示每秒可完成100E次hash(哈希值)计算。
```

本文编写时，时间是 2022 年 11 月 8 日 23:00 China Standard Time UTC+8:00，获取当前区块为[#762286](https://www.blockchain.com/explorer/blocks/btc/762286) ，

全网算力=[296.57EH/s](https://www.coinwarz.com/mining/bitcoin/hashrate-chart) ，则有

```
已知difficulty_762286 = 36,762,198,818,467.21（36*10^12≈36T）
可求#762286出块时间 = 36T * 2^32 / (296.57 * 10^18)
= 36 * 2^32 / (296.57 * 10^6)
= 36 * 4294 / 296.57
≈ 521s
```

另外，Difficulty 还可以与 Target 进行换算，公式为：

> Difficulty_当前区块 = target_创世区块 / target_当前区块

从比特币的 [创世区块](https://www.blockchain.com/explorer/blocks/btc/000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f)

中可以看到，Bits 为 486604799（十六进制为 0x1d00ffff）时，难度值（difficulty）为 1（**注意，区块头中并没有存储 difficulty 的字段**）。根据 Bits，

算出 target 为 0x00ffff * 256^26，即 `0x00000000ffff0000000000000000000000000000000000000000000000000000`。那么仍然以当前区块#762286 为例，

Bits 值为 386,377,746（十六进制为 0x1707A812），target 为 0x07A812 * 256 ^ (0x17-3)，计算其 Difficulty 如下：

```
difficulty_762286 = 0x00ffff * 256^26 / (0x07A812 * 256^20)
= (65535 / 501778) * 256^6
= 36,762,198,818,467.21
```

也就是 36T 左右，与上面链接中查询的 Difficulty 值匹配。

**难度调整**

如前所述，区块头目标 Hash 值（target）决定了难度（difficulty），进而影响比特币的出块时间。根据设计，比特币要保证平均每 10 分钟的区块生成速度，

这是比特币新币发行和交易完成的基础，需要在长期内保持相对稳定。难度调整公式就是前面的**公式 1**， 此外，要注意的是，难度的调整，

是通过调整区块头中的 Bits 字段来实现的，区块头中并没有直接存储全网难度（difficulty）的字段。

#### 1.3 最长链原则

比特币发展至今，全网矿工不计其数，那必然会有多个矿工同时挖出区块并在网络中广播的情况，此时区块链就会发生分叉。而**最长链原则**就是用来应对这个情况的。

> 最长链原则：选择一条最长的链作为主链，矿工挖矿与数据同步都以最长链为标准，如果存在长度相同的链，就从中随机选择一条进行挖矿。存在于在非主链上的区块中的交易，
> 在主链上都不作数，相当于进行了「回滚」。

因为可能分叉的缘故，通常需要等待额外几个区块生成以后，才可以认为当前交易成功写入主链，基本不可回滚。一般来说，在连续生成 6 个区块后，

则认为第一个区块中的交易很难被篡改，可以被认为完成确认。比特币系统中一笔交易的确认时间大约为 1 小时。

最长链原则作为识别主链的方式，被大部分共识算法采用，如 PoW、PoS、DPoS 等。

#### 1.4 PoW 算法实际应用问题

**【51% 算力攻击问题】**

根据前述章节，可以了解到 PoW 算法的核心就是机器的算力，当某人/组织拥有的算力资源足够高，他就拥有足够快的挖矿速度，即打包区块的速度。相当于主链的构建权在他手上。

当他的算力超过全网算力的 50%，那么根据最长链原则，他就拥有让当前主链「回滚」的能力，即他可以控制全部算力资源从较前的区块开始重新打包，以使后面的区块「回滚」。

这也相当于实现了【双花】。

不过，比特币系统发展至今，全网算力已经达到一个非常恐怖的级别，想要控制全网 50% 的算力在实际上几乎是不可行的，或者说所需的经济成本也非常高。并且在 51% 攻击行为被发现后，

还会引发币价下跌，从而导致攻击者自己的财产缩水，这是一种吃力不讨好的行为。

**【算力集中问题】**

随着计算机技术的进步，挖矿手段也发生了很大变化，大致经历了 CPU 挖矿、GPU 挖矿、GPU 集群挖矿、FPGA 挖矿、ASIC 挖矿、ASIC 集群挖矿（矿池），其中 GPU 运算能力是 CPU 的几百倍，

FPGA 是 GPU 的数十倍，ASIC 是 FPGA 的数千倍，多个 ASIC 矿机又可以组成矿池。

单个节点的算力飞速提升，需要使用更加专业的设备才能有效参与挖矿竞争。但这也使得挖矿成本提高，只有计算资源高度集中的矿池才能负担得起这种成本投入。据统计，

世界上规模排名前五的矿池掌握的计算资源占据比特币全网计算资源的一半以上。计算资源的集中，导致理想状态下的去中心化形式越来越难以满足，PoW 的共识的公平性、

去中心化程度开始被破坏。

**【资源消耗问题】**

大量矿机的投入需要消耗大量的电力，截至 2017 年，中国投入到比特币和以太坊挖矿的电力已经超过约旦、冰岛、利比亚等国家，在所有国家和地区的电力消耗排名第 71 为，

造成巨大的资源浪费。

**【吞吐量问题】**

使用 PoW 共识算法的系统，为了尽可能降低分叉概率，区块生成速度相对较慢，交易确认时间长。在比特币系统中，平均需要 10 分钟才能完成一次出块，又要再经过 1 小时才能完成交易确认，

交易吞吐量非常之低，难以满足实际需求。

#### 1.5 PoW 是否解决拜占庭将军问题

我们知道，由于公链系统的开放性，出现拜占庭节点是无法避免的，而 PoW 是如何「解决」拜占庭节点的呢？下面从两方面进行分析：

1. 51% 算力。也就是说，除非攻击者拥有 51% 及以上的算力资源时，才能对主链发起有效攻击。虽然达到这个条件需要一定的成本，但也不是不可能，所以这也可以说是概率问题。
2. 矿工激励。比特币通过矿工奖励机制来提升网络的安全性。矿工挖矿可以获得区块奖励以及记账手续费，使得矿工更希望维护网络的正常运行，任何破坏网络的行为都会损害矿工自身的权益。

因此，即使存在拥有 51% 算力的个人/组织，它们也很难有作恶动机。

如上分析，PoW 算法在理论上是存在拜占庭故障的，只是实际上由于成本和动机问题难以进行。另外，PoW 算法也是一个最终一致性共识算法，不是强一致性算法。对于企业应用，

需要有强一致性算法保证交易的正确性，而不是依靠概率。所以它不适合联盟链和私链。

### 2. PoS 共识算法

前面提到的 PoW 算法由于存在大量资源浪费，导致难以被更大规模的应用接受。对此，人们开始尝试使用股份（stake）作为标准进行记账权的竞争，所以诞生了权益证明（Proof of Stake，PoS）共识算法。

PoS 的思想起源于企业的股份制：一个人拥有的股份越多，其获得的股息和分红也就越高。如果采用这种方式进行区块链系统的维护，则不需要过多资源消耗，也能够使区块链资产有自然的通胀。

节点通过投入一定量的虚拟币参与共识，根据持币情况获得打包新区块的权利，并获得奖励。

本节介绍的是传统 PoS 算法，因为其本身具有一些缺陷，导致后来实际应用时会进行优化，或者说产生新的变体。

#### 2.1 基本概念

- 验证者：在 PoS 中，参与共识的节点被称为验证者节点（Validator）。任何拥有虚拟币的节点都可以通过发送特殊交易的方式，将部分虚拟货币转为股份，以成为验证者。完整的验证者节点集合由区块链系统维护。
- 币龄：为了描述持币情况，PoS 共识算法引入了币龄（Coinage）概念，表示持有部分虚拟货币的时长。当节点将虚拟币作为股份投入后，这部分虚拟币就开始积累币龄，

币龄计算方式：Coinage=k * balance * age; 币龄在使用对应虚拟币（用于区块生成或交易）后会被销毁。节点币龄越大，越容易生成区块。

#### 2.2 共识流程

PoS 算法在打包区块时，将同时考虑币龄和哈希计算难度，使得节点只需要消耗很少的计算资源就可以出块。

#### 2.3 实际应用问题

**【一、Nothing at Stake】**

也叫做无成本作恶。在 PoS 算法中，节点可以很低成本出块，所以无法压制大量分叉行为。

**【二、Long Range Attack】**

也叫长程攻击。指的是从创世区块开始，创建一条比当前主链还长的区块链，并篡改历史交易，用来代替主链。因此也叫历史覆盖攻击。典型的长程攻击有三种：

1. 简单攻击（Simple Attack）。攻击者通过缩短区块生成时间，从而以较快速度在分叉链上生成区块，依次成为最长链代替主链。这种攻击行为较为简陋，可以通过查询异常时间戳进行过滤。
2. 变节攻击（Posterior Corruption）。分叉链验证人通过获得旧验证人的私钥，在分叉链上加速完成超过主链长度的一种攻击方式。发展较长的区块链项目，可能已经更换了几轮验证人，

旧验证人的私钥依旧可以签署以前的旧区块，分叉链验证人可以通过购买、行贿或破解的方式获得旧验证人的私钥，从而签署合理的区块，达到加速的目的。

1. 权益流损（Stake Bleeding）。分叉链验证人通过延长在主链的区块生成时间，同时通过累计分叉链权益，以加快分叉链出块速度的攻击方式。

一般分叉链上的验证人也是原主链上的验证人，当他在原主链上获得出块机会时，验证人会通过某种方式延迟出块或不出块，为分叉链争取出块时间。从而逐渐超过主链长度。

**【三、冷启动问题】**

由于 PoS 共识算法中币龄越大的节点优先获得记账权，所以参与节点都希望囤积虚拟币，很少交易。这就造成了纯粹的 PoS 公链无法冷启动。因此，实际运行时，

一般采用 PoW 算法启动区块链系统，再切换到 PoW+PoS 方式，最后切换到完全的 PoS。在 2022 年 9 月 15 日，以太坊主网完成了从 PoW 向 PoS 过渡的阶段，也就是合并 Beacon 链。

#### 2.4 PoS 算法应用

- 点点币（Peercoin）是首个采用 PoS 算法的虚拟货币，它采用 PoW+PoS 的混合共识机制。
- 未币（NXT）是一个完全使用 PoS 算法的公链虚拟货币系统。
- Tendermint 区块链采用押金投票机制来避免无成本作恶问题，同时也能够在不超过 1/3 的拜占庭节点存在情况下保证共识一致性和正确性，是第一个能在理论上证明拜占庭容错的 PoS 协议。
- LPoS 协议。传统 PoS 的缺点是「穷节点」只有渺茫的机会获得记账权，意味着很多币少的节点没有动力运行，网络就基本由小部分大玩家维持。这样会导致网络的安全性变差，

因为一个安全的区块链系统需要大量节点参与，所以需要激励小权益节点参与记账。LPoS(Leased PoS)租借权益证明可以解决这个问题，它让权益人将自己的余额租借给别的节点来出块，

租借的代币仍然由权益者控制，可以在租借到期后花掉或转移。出块后的收益由租借人和出块者共享。Waves 是采用 LPoS 的区块链项目。

- DPoS 协议，下节中介绍。

### 3. DPoS 算法

不管是 PoW 还是传统 PoS 算法，随着项目发展，它们都逐渐具有一定的中心化特性，即拥有高算力或高代币余额的节点优先拥有记账权，DPoS 的出现解决了这个不足。

DPoS 最早由 BitShares、Steemit 以及 EOS 的创办人 Dan Larimer 在 2014 年提出并应用，他在区块链项目 BitShares 中实现了 DPoS 共识机制。

> DPoS 的设计者认为，从规模化角度看，PoW 和 PoS 算法都有走向委托制的倾向，存在中心化风险。因此，不如在一开始就设计好如何进行权益分配与权力制约，有利于系统更好的运行，
> 从而避免被动演化导致不可预期的结果。

DPoS 是目前看到的最快、最高效和最灵活（但不去中心化）的共识算法。委托权益证明（Delegated Proof of Stake, DPoS）利用权益人投票的权利来公平民主的解决共识问题。

DPoS 是一种基于投票选举的共识算法，有点像民主大会，持币人选出几个代表节点来运营网络， 用专业运行的网络服务器来保证区块链网络的安全和性能。

DPoS 机制中，不需要算力解决数学难题，而是由持币者选出谁做生产者，如果生产者不称职，就有随时有可能被投票出局，这也就解决了 PoS 的性能问题。

#### 3.1 DPoS 的优缺点

**优点**

- 不需要耗费能源和硬件设备；缩短了区块的产生时间和确认时间，提高了系统效率。
- DPoS 不需要挖矿，也不需要全节点验证，而是由有限数量的见证节点进行验证，因此简单、高效。

**缺点**

- 为了提高效率，DPoS 以代理人共识取代全网共识，因此时常被抨击与区块链去中心化的理念相违背。

#### 3.2 基本概念

**【候选人】**

只要满足基本条件就可以成为候选人，参与见证人竞选。在竞选之前，候选人需要注册独有的身份，这个身份将被用于节点选举。在与身份相关的结构中，将保留个人的状态信息及详细介绍，

以供投票人参考。

**【投票人】**

只要节点持有货币，就可以作为投票人根据自己设置的条件向自己认可的候选人投票。

**【见证人】**

见证人是直接负责打包区块的节点。

**【受托人】**

在早期的 DPoS 项目 BitShares 中，还有受托人（Delegates），它也是投票产生的，其主要功能是维护系统各项参数，如打包区块的时间间隔等。

而在后期的 DPoS 项目 EOS.io 中，只保留了见证人。

#### 3.3 共识流程

DPoS 的共识流程主要就是投票选出见证人，并由见证人轮流进行区块生成的循环流程。系统在每轮循环中都会重新统计候选人得票，并选出 N 个见证人，并把它们的排序打乱，

然后见证人轮流生成区块。在一个生成周期结束后，再重新进行见证人选举。在使用 DPoS 算法的不同项目中，会对具体流程做优化，下面只对相关主流程做大致说明。

**【候选人注册】**

候选人提供必要的信息标识以注册身份，以及提供接口使得外界可以获取到当前候选人状态。其次，候选人还需要提供个人介绍、网站等额外信息以供投票人参考。

此外，候选人注册支付一定费用，一般这笔费用是生成单个区块奖励的上百倍。所以候选人在成为见证人后，需要生成上千个区块才能达到收支平衡，这就防止了候选人不认真履行生成区块的责任。

**【投票】**

为了对候选人进行投票，每个投票人都会记录必要的信息，包括可信代表（Trusted Delegates）、非可信代表（Distrusted Delegates）等。可信代表用于记录投票人信任的代表节点；

非可信代表用于记录投票人不信任的代表节点。投票时，投票人可以从尚未成为见证人的可信代表中，选择最有可能成为见证人的节点投出支持票；或者从已经是见证人的非可信代表中，

选择其中一个进行反对。

此外，投票人还会根据候选人成为见证人后的表现进行评分，维护可见代表（Observed Delegates）的列表，并根据分数统计排名。对于一个 DPoS 区块链系统，由系统负责记录当前见证人的顺序，

后续每轮区块产生的顺序都与此相关。同时，社区会维护当前候选人的排名（Ranked Delegates），这个排名根据投票情况产生。

**【区块生成】**

DPoS 区块链系统的见证人顺序是公开的。每当候选人的排名更新时，见证人列表也会更新，并随后打乱顺序。根据当前的见证人顺序和当前时间，可以计算每个见证人生成下一个区块的时间表。

当达到某个时刻时，对应的见证人进行区块签发，其他节点也可以根据这个时间表进行验证。

### 4. PBFT 算法

由于应用于公链的 PoW 和 PoS 等算法的吞吐量低且交易确认延迟高等问题，无法在实时性要求高的场景中使用。而在联盟链场景中，节点数量相对较少，且对交易吞吐量以及交易确认的实时性要求高，

因此需要更合适的共识算法。PBFT 算法在 1999 年被提出，叫做「实用拜占庭容错」算法，它降低了拜占庭协议的运行复杂度，从指数级别降低到多项式级别。使得拜占庭协议在实际场景中应用成为可能。

PBFT 算法主要应用在节点较少，且要求高吞吐量的区块链系统中，如联盟链和私链。

PBFT 是一类状态机拜占庭协议，要求整个系统共同维护一个状态，所有节点采取的行动一致。算法中主要运行三类基本协议：一致性协议、检查点协议和视图更换协议。

我们主要关注支持系统日常运行的一致性协议。

#### 4.1 一致性协议

一致性协议要求客户端发出的请求在每个服务器节点上都按照一个确定的顺序执行。这个协议把服务器节点分为两类：1 个主节点和多个从节点。其中主节点负责将客户端的请求排序，

从节点按照主节点提供的顺序执行请求。所有节点在相同的配置下工作，该配置称为试图，主节点更换则视图随之变化。

一致性协议包含 5 个阶段：请求（Request）、序号分配（Pre-Prepare）、交互（Prepare）、序号确认（Commit）和响应/执行（Reply/Execute）。

![](static/Ht0JblP50ojX6ixnKmacP09FnWD.png)

上图中节点 3 是拜占庭节点，故意不与其他节点交互。

PBFT 假设系统有拜占庭节点数 f 个，所有节点至少为 3f+1。每个客户端的请求都会经过 5 个阶段，通过采用两两交互的方式在服务器之间达成共识后再执行客户端请求。

如果服务器在一段时间内都不能达成共识，则会触发视图更换协议（超时机制）。

**【1.Request（请求）阶段】**

客户端发生请求给主节点，请求消息 m=[op,ts,c-id,c-sig]，其中 op 是需要执行的操作，ts 是时间戳，c-id 是客户端 ID，c-sig 是客户端签名。时间戳是为了保证命令只被执行一次，

客户端的签名是方便客户认证和权限控制。

**【2.Pre-Prepare（序号分配）阶段】**

主节点会给请求分配一个序列号 sn，并构造 Pre-Prepare 消息[PP,vn,sn,D(m),p-sig,m]给其他从节点，其中 PP 表示 Pre-Prepare 消息，vn 是视图号，D(m)是消息摘要，

p-sig 是主节点签名，m 是客户消息。序列号是为了保证命令执行顺序，视图号让从节点记录当前视图，主节点签名是为了让从节点认证主节点身份，而消息摘要是为了保证消息没有篡改。

**【3. Prepare（交互）阶段】**

从节点接受 PP 消息，然后向其他从节点广播 Prepare 消息[P,vn,sn,D(m),b-id,b-sig]，其中 P 表示 Prepare 消息，b-id 是从节点 ID，b-sig 是从节点签名。

**【4. Commit（序号确认）阶段】**

从节点在收到 2f+1 个 Prepare 消息后，对视图内的请求和次序进行验证，然后广播 Commit 消息[C,vn,sn,D(m),b-id,b-sig]，其中 C 表示 Commit 消息。

**【5. Reply/Execute（响应）阶段】**

当各节点收到 2f+1 个 Commit 消息后，它们将执行操作并提交，同时把回复返回给客户端。回复消息是[R,vn,ts,b-sig]，R 是回复消息。客户端等待不同节点的回复，

若有 f+1 个回复一致，则接受该回复。

#### 4.2 PBFT 不违背 FLP 定理

仔细观察，会发现 PBFT 的设计包含了超时机制，相当于一种同步通信模型。在超时机制下，PBFT 能够保证安全性和活性。

#### 4.3 PBFT 的应用

PBFT 一般应用在需要强一致性的联盟链和私链场景中。例如，在 IBM 主导的超级账本项目中，PBFT 就是一个可选的共识协议。Fabric 0.6 版本自带 PBFT。

除了 PBFT，它还引入了基于 PBFT 的自用共识协议，目的是希望在 PBFT 基础之上能够对节点的输出也做好共识。

其他的拜占庭容错共识算法还有 Fab Paxos、XFS、Zyzzyva、SBFT 等。

#### 4.4 PBFT 小结

由于 PBFT 是强一致性算法，所以不可能出现分叉行为。不过相较于前面的共识算法，PBFT 的实现难度较高，对主节点有较高的负载压力，如果不考虑拜占庭行为，

则可以优先考虑 Raft 等轻量级的共识算法。

### 5. Casper 共识算法

#### 5.1 背景

由于工作量证明（PoW）算法面临的多项挑战，权益证明（PoS）共识算法于 2011 年 7 月在 Bitcointalk 论坛首次被提出。随着时间的推进，PoS 算法已经发展成两个主要的分支：

1. 基于链的权益证明（Chain-Based PoS）：

   - 这种形式的 PoS 算法在每个设定的时间段（例如，每 10 秒）通过伪随机方式选取区块提议者生成新区块。每个新区块必须指向链上已有的某个区块，从而随时间推移所有区块逐渐形成一条单一链。这种方式模拟了挖矿过程，但避免了传统 PoW 中的资源浪费，同时提高了共识的效率。Peercoin、Blackcoin 和由 Iddo Bentov 等人开发的项目采用了这种算法。
2. 基于拜占庭容错的权益证明（BFT-Based PoS）：

   - Tendermint 团队在 2014 年提出了这种结合了经典 PBFT 共识特性的 PoS 算法。它保留了以下核心特性：
     - 极短的最终确定时间（Finality）：通过两轮共识投票机制快速达成最终共识，一旦区块被确认，它便立即成为最终确定的，意味着区块是不可逆的并且安全地加入到链上。
     - 数学证明的安全性：该算法能够保证，只要超过三分之二的资产掌握在诚实参与者手中，无论网络条件如何，都可以确保最终确定的区块之间无冲突。

随着时间的发展，一系列基于 BFT 的 PoS 共识算法相继被开发，包括 Casper、Ouroboros 和 Algorand 等。这些算法不仅为区块链共识提供了新的方向，也为系统的可扩展性和环境友好性开辟了新径。

#### 5.2 基本介绍

随着权益证明（PoS）算法的兴起，以太坊逐渐转向这种共识机制。Casper 共识算法是最早由以太坊核心研究员 Vlad Zamfir 提出的，其名字来源于 20 世纪 90 年代的喜剧电影_Casper_。2017 年 10 月，以太坊创始人 Vitalik Buterin 又提出了另一种 Casper 共识算法。为了区分两者，前者被称为 Casper CBC（Correct-by-Construction），后者被称为 Casper FFG（Friendly Finality Gadget）。在以太坊内部，有两个团队分别研究这两种 Casper 共识算法。

##### 一、Casper CBC（Correct-by-Construction）

Casper CBC 是一组共识协议，目标是构建一个抽象但足够灵活的框架，以支持在其基础上逐步增加和构建协议的定义，并无缝集成所有理论证明和保证（如安全性和活性）。Vlad Zamfir 称这种方法为“构建中修正”（Correct-by-Construction），即在协议构建过程中确保其正确性。Casper CBC 是一种完全 PoS 化的共识算法。

##### 二、Casper FFG（Friendly Finality Gadget）

除了资源浪费和共识效率低的问题，PoW 还存在一个隐含问题，即没有明确的最终确定时间。具体来说，PoW 共识算法不能为任何非创世区块提供严格的数学证明以证明其正确性，只能提供一定的概率保证，确保已上链的交易不会因双花问题而逆转（因 51% 攻击的理论存在）。Casper FFG 共识算法就是为了解决这个问题而设计的。

Casper FFG 可以与任何具有树形结构的区块链协议配合使用，后者负责出块共识，前者用于显式地确定区块。FFG 确保最终确定的区块将不可逆转地上链且没有冲突，因此 FFG 是一种结合了 PoW 和 PoS 两者优势的共识算法。

为了安全、平稳地切换共识算法，以太坊 2.0 初期采用了 FFG 方案，以实现从 PoW 到完全 PoS 共识的渐进过渡。下文将重点介绍 FFG 的具体设计。

#### 5.3 FFG 基本概念

##### 一、Validator（验证者）

在 FFG 共识算法中，Validator（验证者）负责投票产生 checkpoint 区块。成为 Validator 需要通过智能合约在系统中存入最低限度的保证金。Validator 通过持续参与共识过程可以获得奖励，增加其保证金数额；相反，如果进行恶意行为，系统将减少其保证金以示惩罚。Validator 若想取回保证金，必须通过智能合约发出销毁命令。

##### 二、Finality（最终确定性）

达到最终确定性的交易或区块将不可逆转地上链，不存在回滚和冲突的可能性。

##### 三、Epoch（世代）

为降低 PoS 的 checkpoint 数量，FFG 算法将每 100 个区块划分为一个 Epoch。Validator 在每个 Epoch 的边界内对区块集合进行投票和验证。

##### 四、Checkpoint

在 FFG 算法中，Validator 会定期对 Epoch 边界内的区块进行投票。最终确定的区块将被虚拟机执行并写入账本，这些被选中的区块称为 checkpoint。所有的 checkpoint 最终会组成一颗 checkpoint 树（checkpoint-tree）。

#### 5.4 FFG 共识流程

下图是 Casper FFG 架构图，虚线代表中间隔了若干区块或 checkpoint。

![](static/EqeFb1nTsoZIbvxSwpbc6nAYnUh.png)

FFG 可以与任何具有树形结构的区块链协议一起使用。如上图所示，基础链呈树形结构，每 100 个区块组成一个 Epoch。Validator 节点负责在每个 Epoch 的边界构造和达成 checkpoint 共识，从而实现显式的最终确定性。

在网络延迟或遭受攻击的情况下，基础链可能会产生分叉，即一个父区块可能会有多个子区块。FFG 假定基础链的共识协议拥有自己的分叉选择原则，所有 Validator 节点在每个 Epoch 边界也会运行一次分叉选择原则，以确定在哪个区块上构建 checkpoint。例如，上图中，区块 99 存在两个兄弟区块，这是分叉的情况，最终 Validator 选择了区块 99 来构建 checkpoint。

**【checkpoint 链分叉】**

由于网络延迟、攻击，甚至恶意 Validator 节点等问题，不同的 Validator 节点在运行基础链的分叉选择时可能会得到不同的结果，导致在同一高度的基础链上存在多个不同的 checkpoint。

如下图所示，创世区块对应一个 checkpoint，此后每 100 个区块的高度也会形成一个 checkpoint。Validator A 节点和 B 节点在同一高度发布了不同的 checkpoint。显而易见，这些 checkpoint 最终会形成一颗 checkpoint 树。

为了确保一致性，FFG 会在这棵 checkpoint 树中根据 LMD-GHOST 规则（Latest Message Driven Greediest Heaviest Observed Subtree）选择出一条路径，作为 checkpoint 主链。这样可以确保在分叉的情况下，系统依然能够达成共识并保持链的稳定性。

![](static/IcRibKUk4oWRjaxqpHtcBI6Inbx.png)

**FFG 中的共识**指的就是所有 Validator 节点形成对 checkpoint 主链的共识。针对 checkpoint 的投票验证过程，还有更多细节，限于篇幅，此处不再赘述。

读者如有兴趣可自行查阅 [FFG 论文](https://arxiv.org/abs/1710.09437) 。

#### 5.5 LMD-GHOST 协议

如前所述，不同的 Validator 节点可能会在同一区块高度发布不同的 checkpoint 区块，导致 checkpoint 链分叉，从而形成 checkpoint 树。由于长程攻击的风险，传统的最长链原则不再适用于 PoS 算法。因此，FFG 引入了 GHOST 协议来解决 checkpoint 的分叉问题。

LMD-GHOST（Latest Message Driven Greediest Heaviest Observed SubTree）是 FFG Validator 节点遵循的分叉选择规则。具体来说，在每个 Epoch 结束后，Validator 节点都会基于自己观察到的区块，采用贪心算法选取最重（即资产权重最高）的子树作为主链。

例如，在同一高度存在多个区块的情况下，Validator 节点会投票选择其中资产权重最高的区块作为 checkpoint。这一规则确保了系统能够在分叉的情况下仍然达成共识，并保持链的稳定性和安全性。

#### 5.6 实际应用

Casper FFG 在尽可能提供一致性的同时保证系统的活性，目前已在以太坊 2.0 中上线，其最终目标是过渡到完全的 PoS 共识（可能是 Casper CBC）。

## 五、共识算法总结

本教程详细讨论了传统分布式一致性算法和区块链场景中使用的共识算法。从解决拜占庭将军问题的经典入门，本文逐步深入到各种一致性协议和共识算法的复杂世界。

在分布式系统的早期，常见的一致性算法包括 2PC 和 3PC 等。这些算法虽然模型简单，适用于同步通信模型和非拜占庭环境，但在网络分区发生时常会遇到数据不一致的问题，这在生产环境中是不可接受的，因为它们在保证安全性（Safety）和活性（Liveness）之间缺乏平衡。

1990 年，Paxos 算法的出现标志着在异步网络中保证安全性的同时，能够在网络恢复同步后保持活性的共识模型的诞生。尽管 Paxos 方案在理论上具有划时代的意义，但实际应用较少，主要是因为其实现的复杂性。随后，基于 Paxos 的一系列变体算法如 Raft、Chubby、Zookeeper 和 etcd 被开发出来，以便于理解和实现。

1993 年，工作量证明（PoW）算法被提出，最初设计用于防止电子邮件垃圾，直到 2008 年比特币的出现，PoW 才广为人知。PoW 的核心优势在于通过解决计算密集型问题来增加作恶成本，并通过矿工奖励机制来降低系统中恶意节点的概率，支撑了去中心化的网络结构。然而，PoW 因其巨大的能源消耗而受到批评，这促使了权益证明（PoS）算法的发展，该算法利用持有者的股份作为参与记账的资本，减少了能源消耗。

尽管 PoW 和 PoS 提供了解决方案，但它们在实现中倾向于中心化并且处理速度较慢。为此，2014 年，委托权益证明（DPoS）算法应运而生。DPoS 通过选定少数代理进行共识，有效提高了系统的处理能力，达到了每秒 10 万笔交易。多个项目已经使用 DPoS 运行多年，证明了其作为一种可靠共识机制的有效性。

除此之外，1999 年提出的实用拜占庭容错（PBFT）算法解决了拜占庭容错的复杂性问题，尤其适用于联盟链和私链场景，这是因为它能够在一定的同步网络条件下运行，容忍不超过系统三分之一的恶意节点，同时提供出色的系统吞吐量，使其成为一种强一致性共识算法的典范。


# 区块链密码学简介

## 一、对称密码算法

**概述**

对称密码算法的主要特点是使用相同的密钥进行加密和解密。这类算法根据其加密方式大致可以分为两类：流密码和分组密码。区块链技术主要采用分组密码。流密码以数据流的形式逐位或逐字节加密，而分组密码则将数据分成固定大小的块进行加密。

**知名的对称密码算法包括：**

- **DES（Data Encryption Standard）：** 较老的加密标准，现已被认为不够安全。
- **3DES（Triple DES）：** 是 DES 的一个更安全的变体，通过三次加密过程增强安全性。
- **IDEA（International Data Encryption Algorithm）：** 一种强大的加密算法，常用于商业加密软件。
- **RC2, RC4, RC5：** 由 Ron Rivest 设计的一系列加密算法，其中 RC4 尤其流行，虽然现在被认为存在安全性问题。
- **Blowfish：** 是一种块加密算法，设计用来替代 DES。
- **AES（Advanced Encryption Standard）：** 现代加密标准，提供了高级的安全性，是目前使用最广泛的加密算法之一。

### 1. 流密码

- RC4：曾广泛用于 WEP 网络加密。
- SNOW 3G：在 3G 数据传输中用作加密算法。
- A5：用于 GSM 系统的加密。
- 祖冲之序列密码：在 4G 通信中用于加密。

### 2. 分组密码

**概述**

分组密码是一种将长明文序列切分为固定长度段后，对每个段分别进行加密的方法。这类算法不仅用于加密数据，还广泛应用于构造随机数生成器、流密码、消息认证码（MAC）和哈希函数等。由于其安全性和高效性，分组密码算法如 DES、IDEA、AES 等得到了广泛的应用。

#### 2.1 DES

- 开发与采用：DES 由美国 IBM 公司于 1992 年研制，基于现代密码学的基本理念。1976 年，它被美国国家标准局确认为联邦信息处理标准（FIPS），随后在全球范围内广泛使用。
- 技术细节：DES 的工作包括三个主要参数：密钥（key）、数据（data）和工作模式（mode）。加密过程中，数据以 64 位为一组进行处理，而 56 位的密钥用于加密或解密这些数据块。
- 安全性和遗留问题：尽管 DES 在早期被广泛使用，但其 56 位的密钥长度已不足以抵抗现代的攻击手段。例如，1999 年一个 DES 密钥在 22 小时 15 分钟内就被公开破解。尽管有理论上的弱点，实际中利用这些弱点进行攻击非常困难。为了提高安全性，可以使用 DES 的增强版本 3DES，虽然它也有已知的理论攻击方法。
- 替代和淘汰：DES 标准及其衍生算法 3DES 已逐步被更现代、安全的高级加密标准（AES）所取代。DES 自 1977 年发布以来服务了超过 20 年，直到 2000 年 AES 的推出，它才正式被新的加密标准所替代。

> **DES 现在已经不是一种安全的加密方法**，主要因为它使用的 56 位密钥过短。1999 年 1 月，distributed.net 与电子前哨基金会合作，
> 在 22 小时 15 分钟内即公开破解了一个 DES 密钥。也有一些分析报告提出了该算法的理论上的弱点，虽然在实际中难以应用。为了提供实用所需的安全性，
> 可以使用 DES 的派生算法 3DES 来进行加密，虽然 3DES 也存在理论上的攻击方法。DES 标准和 3DES 标准已逐渐被高级加密标准（AES）所取代。
> 另外，DES 已经不再作为国家标准科技协会（前国家标准局）的一个标准。

DES 自 1977 年公布后服务了 20 多年，直到 2000 年高级加密标准（AES）公布，替代 DES 成为新的加密标准。

#### 2.2 AES

**概述**

AES（高级加密标准）是一种加密标准，基于 Rijndael 加密算法，由美国国家标准与技术研究院（NIST）在 2001 年 11 月 26 日正式发布为 FIPS PUB 197 标准。

**技术细节**

- 分组长度：AES 算法将数据分组长度固定为 128 比特，以确保加密处理的统一性和效率。
- 密钥长度：AES 支持多种密钥长度选项，分别为 128 比特、192 比特和 256 比特。根据使用的密钥长度，AES 分为三个变体：AES-128, AES-192, 和 AES-256。
- 加密轮数：加密过程中的轮数（N）根据密钥长度不同而不同。AES-128 使用 10 轮加密，AES-192 使用 12 轮，而 AES-256 则使用 14 轮。这些加密轮数设计用于增强算法的安全性，使其能够抵御各种密码攻击。

**应用和安全性**

AES 因其强大的安全性和高效的性能成为了全球使用最广泛的加密标准之一。它被广泛应用于政府、金融和商业数据保护中，提供了一种坚固的防护措施，以防数据被未经授权的访问和窃取。

#### 2.3 分组密码工作模式

**概述**

分组密码工作模式不是一种加密算法，而是描述如何在一个加密算法中重复使用密钥的方法。这些模式与加密算法如 DES 和 AES 搭配使用，以隐蔽明文的统计特性和数据格式，提高整体安全性，并降低数据被篡改、重放、插入和伪造等攻击的成功机会。

**主要工作模式**

1. **ECB（Electronic Codebook）**

   - 描述：最简单的模式，单独加密每个 128 位明文分组，每个分组使用相同的密钥。
   - 优点：简单，支持并行计算，没有误差传播。
   - 缺点：相同明文分组产生相同密文分组，可能暴露固定内容的明文。
2. **CBC（Cipher Block Chaining）**

   - 描述：明文分组在加密前与前一个密文分组进行异或操作。
   - 优点：安全性较高。
   - 缺点：存在错误传播，不支持并行计算。广泛应用于 SSL 和 IPSec。
3. **CFB（Cipher Feedback）**

   - 描述：将分组密码转化为流密码模式，使用前一密文分组的部分比特和秘钥进行加密。
   - 优点：适合加密小分组数据，通过更换初始向量（IV）可以有效隐藏明文内容。
   - 缺点：存在比特级的错误传播。
4. **OFB（Output Feedback）**

   - 描述：与 CFB 类似，但本次加密的输入是上一次加密的输出。
   - 优点：没有错误传播，解决了 CBC 和 CFB 的错误传播问题。
   - 缺点：需要频繁更换密钥或初始向量。

### 3. 对称密码算法小结

**核心特性**

对称密码算法的主要优势在于其开放性、低计算需求、快速加密速度和高加密效率。这些特性使得对称加密在需要快速处理大量数据的场景中非常有用。

**安全性挑战**

然而，对称加密也存在一些显著的安全挑战：

- **密钥管理：** 由于加密和解密使用相同的密钥，因此保证密钥的安全变得尤为重要。密钥在双方之间共享，必须通过绝对安全的通道传输，否则安全性无法保障。
- **密钥泄露风险：** 密钥的安全性高度依赖于其保存方式。如果密钥由多人知晓，泄露的风险显著增加，这可能导致加密信息的安全性大打折扣。

**总结**

虽然对称加密算法在性能上表现出色，但在使用过程中必须采取额外的安全措施来保护密钥，确保加密数据的安全性。密钥管理的策略和工具是保证对称加密算法有效安全运用的关键因素。

### 4. 对称密码算法在区块链中的应用

虽然对称密码算法因其固有特性在区块链技术中的应用场景相对较少，但它在某些关键领域中扮演着重要角色。

**1. 数字钱包中的私钥管理**

在数字钱包的设计中，对称密码算法是保护用户私钥的一种常用手段。根据钱包的去中心化程度，可以分为全节点钱包、轻节点钱包和中心化钱包。这些钱包均具备密钥存储功能，即使用对称加密方法将用户的私钥、公钥和账户地址安全地存放在加密文件中。用户通过设置对称加密密码来访问和管理这些密钥。即便这些加密文件被泄露，由于对称加密的保护，私钥信息仍能在一定时间内保持安全。然而，一旦加密文件被泄露，用户应立即将资产转移至新的私钥对应的账户地址，并重新安全保存新的加密文件。

**2. 区块链网络层通信**

对称密码算法还广泛应用于区块链网络层的通信安全中，特别是在 TLS（传输层安全协议）中。TLS 利用对称加密算法来保证数据传输过程中的机密性和完整性，确保区块链网络通信不受中间人攻击和监听的威胁。

通过这些应用，对称密码算法在确保区块链技术的安全性和可靠性方面发挥了重要作用，特别是在提升交易和通信的安全性方面。

> 比特币官方使用 AES 加密用户的私钥文件。

## 二、非对称密码算法

**概述**

非对称密码算法，通常称为公钥加密算法，主要用于解决对称密码算法在认证和签名场景中的限制。这类算法使用一对密钥：一个公钥和一个私钥。这两个密钥具有互补性，即用其中一个密钥加密的信息，只能用另一个相应的密钥解密。

**特点与应用**

非对称密码算法在加解密效率上通常稍慢于对称密码算法，但提供了更高的安全性，特别是在数字签名和安全通信领域。这使得它们非常适合需要高安全性的场景。

**常见算法**

1. **RSA：** 基于大质因数分解难题，是最广泛使用的非对称加密算法之一。它既可用于加密数据，也常用于数字签名。
2. **Diffie-Hellman：** 专注于密钥交换，基于离散对数难题，允许两个无先前联系的方在不安全的通道上共享密钥。
3. **ElGamal：** 同样基于离散对数难题，提供加密和数字签名功能。
4. **ECC (Elliptic Curve Cryptography)：** 椭圆曲线密码算法，基于椭圆曲线上的离散对数问题。它因密钥长度较短而提供相同级别的安全保证，从而在效率上优于 RSA。ECC 被广泛用于移动设备和智能卡等资源受限环境。

**深入介绍：RSA 与 ECC**

- **RSA：** 首选于 1987 年由 MIT 研究人员提出，它的安全性依赖于大数分解的困难性，使得在实际应用中，如 SSL/TLS 协议中非常有效。
- **ECC：** 1985 年提出，已成为数字证书和区块链技术中的标准选择。ECC 不仅用于加密，也是生成区块链地址和执行数字签名的核心技术，如 Bitcoin 等主要加密货币使用的 ECDSA（基于椭圆曲线的数字签名算法）。

**总结**

非对称密码算法通过其独特的密钥结构提高了交易和通信的安全性。尽管在处理速度上可能不如对称密码算法，但其在保证数据安全性方面的能力使它在处理敏感和重要信息时成为不可或缺的工具。

## 三、Hash 函数

哈希函数，也称为散列函数或单向加密算法，是一种将任意长度的输入数据转换成固定长度输出的函数。这些输出通常表现为一个较短的、固定长度的值或摘要，常用于确保数据的完整性。哈希函数的特点是高效且能快速地处理大量数据，同时其输出不易被逆向工程还原原始输入信息。

常见 Hash 函数有 MD4/MD5、RipeMD-160、SHA 系列函数以及 SM3 国密算法。

> MD5 和 SHA1 都被攻破，不能用于要求安全性较高的场景，区块链使用了 SHA-256 算法；

### 1. SHA

SHA 包含 SHA-[0~3]共四个系列，见下图（来自维基百科）

![](static/NwrMbmx2qojutexD6Z6cBu6tnCg.png)

SHA 系列应用在很多安全协议中，如 TLS、SSL、PGP、SSH、S/MIME 和 IPSec 等。

#### 1.1 Keccak 介绍

**简介**

Keccak 是一种革命性的加密哈希函数，由 Guido Bertoni、Joan Daemen、Michaël Peeters 和 Gilles Van Assche 四位专家设计。在 2012 年，它赢得了由美国国家标准与技术研究院（NIST）举办的 SHA-3 竞赛，随后被正式采纳为 SHA-3 标准。与传统的 SHA 算法不同，Keccak 采用了独特的“海绵结构”。

**海绵结构**

Keccak 的核心特征是其采用的海绵函数结构，这使得它能够输出可变长度的哈希值。这种结构分为两个主要阶段：

- **吸收阶段：** 在此阶段，输入数据被切割成固定大小的块，每个块依次与内部状态进行异或操作后，通过一个非线性的变换函数（通常是置换或混淆函数）更新内部状态。
- **挤出阶段：** 完成吸收后，内部状态通过多次迭代处理，最终输出最终的哈希值。输出长度可以根据实际需要调整，使其非常灵活。

**Keccak 的特性**

- **灵活性：** Keccak 允许用户自定义内部状态的大小和输出的长度，使其能够根据不同的安全需求和应用场景进行调整。
- **安全性：** Keccak 设计上的独特性提供了出色的抗碰撞性和抗预映射攻击的能力。
- **性能：**在硬件实现中，Keccak 显示出卓越的性能，特别适合于资源受限的环境，如物联网设备中。

**总结**

Keccak 作为 SHA-3 的胜出算法，不仅因其独特的加密结构和优异的性能受到认可，也因其高度的灵活性和强大的安全特性在各种应用场景中展现了巨大的潜力。

### 2. RipeMD-160

**概述**

RipeMD-160 是一种在 1996 年设计的哈希算法，基于 MD4 的设计原理开发。它是 RipeMD 系列中的一个增强版本，旨在提供比 MD4、MD5 和 RipeMD-128 更高的安全性，主要用于替代这些较早期的算法。

**特点**

- **安全性提升：** RipeMD-160 提供 160 位的输出，比 MD5 的 128 位输出更加安全，有效减少了碰撞的可能性。
- **应用场景：** 由于其增强的安全特性，RipeMD-160 常用于需要较高安全性的应用，如数字签名和区块链地址生成。

**其他版本**

- RipeMD-256/320：这两个版本提供更长的输出长度，分别是 256 位和 320 位，设计用于需要更高安全级别的场景。尽管它们提供了更强的安全性，但计算效率相对较低，因此在选择使用这些版本时需要根据具体的应用需求和环境进行权衡。

**总结**

RipeMD-160 及其变体如 RipeMD-256 和 RipeMD-320，提供了从基本到高级的安全选项，使它们适用于不同的技术和业务需求。在选择合适的哈希算法时，需要考虑安全性与效率之间的平衡，以确保最佳的性能和安全性。

### 3. Hash 函数在区块链中的应用

Hash 函数在区块链中有着广泛的应用，主要场景包含账户地址生成、Merkle 树、交易 ID 生成等。

## 四、PKI

公钥基础设施（PKI）是一种综合性的框架，设计用于支持公钥加密和数字证书的管理。它包含了硬件、软件、人员、政策和程序等多个组成部分，涵盖密钥和数字证书的生成、管理、存储、分发以及撤销等全方位功能。

### 1. PKI 组成

一个典型的 PKI 包括 PKI 策略、软硬件系统、CA（Certificate Authority，证书机构）、RA（Registration Authority，注册机构）、证书发布系统和 PKI 应用等。

#### 1.1 PKI 策略

**概述**

PKI 策略为组织提供了一个全面的信息安全框架，明确了使用密码学系统的方法和原则。这些策略不仅定义了如何管理和应用加密技术，还确保了整个组织的信息安全实践的一致性和可靠性。

**主要类型**

PKI 策略通常包含以下两种主要类型的指导方针：

1. **证书策略：**

   - 此策略规定了数字证书的使用条件和约束，包括证书的申请、审批、发放、使用及终止的规则。它为证书的生命周期管理提供了明确的标准和要求。
2. **证书操作声明（Certificate Practice Statement, CPS）：**

   - CPS 详细描述了证书颁发机构（CA）的运作方式，涵盖证书的签发、吊销和管理流程。此外，CPS 还规定了用户密钥的生成、存储和传递方式。
   - CPS 的透明度使得外部利益相关者能够评估 PKI 的可信度和安全性。这份声明为 PKI 实践提供了可信赖的基础，保障了用户和机构对 CA 操作的信任。

**总结**

通过明确的证书策略和详尽的证书操作声明，PKI 策略不仅增强了组织内部的信息安全管理，也提升了外部对组织 PKI 系统可靠性的信心。这种策略的制定和执行对于确保数字身份的安全性和数据交换的完整性至关重要。

#### 1.2 CA

**概述**

证书颁发机构（CA）是公钥基础设施（PKI）的信任基础。CA 负责发放数字证书、设置证书的有效期、管理证书吊销列表（CRL）以实现证书的吊销、管理用户密钥等任务。CA 掌管公钥的整个生命周期，涵盖签发、吊销和更新数字证书等各个环节。

**数字证书**

数字证书是用于证明公钥拥有者身份的电子文件，包含公钥信息、拥有者的身份信息以及 CA 对这份证书的签名等信息。用户可以通过浏览器查询启用 HTTPS 的网站的证书信息。ITU-T（国际电信联盟电信标准化部门）规定了统一的证书格式 X.509，目前包括 V1、V2 和 V3 三个版本。

**证书吊销列表（CRL）**

CRL 用于验证证书的有效性。证书被吊销后，CA 通过更新 CRL 来通知相关方哪些证书已失效。X.509 标准规定了 CRL 的格式。

**双证书服务**

在单证书服务中，数字证书主要用于签名。然而，许多 CA 提供双证书服务，即在提供签名证书的同时，还为用户生成一张加密证书。加密证书中存储了一个对称加密密钥，该密钥通常由签名证书中的公钥派生而来。加密证书产生后，使用签名证书中的公钥进行加密，并与签名证书一起发给用户。用户可以使用私钥对加密证书进行解密，以获得加密密钥。

- **单证书服务：** 网站使用签名证书进行私钥签名和公钥加密（数据传输）。
- **双证书服务：** 签名证书仅用于签名以便用户验证网站身份，加密功能则由加密证书中的密钥负责。此外，CA 通常会留存加密证书中的密钥，以便政府监管和在网站遗失加密证书时申请恢复。

**密钥管理中心（KMC）**

密钥管理中心（KMC）是 CA 中的一个组件，负责密钥的生成、管理、更新、恢复和查询。KMC 通常在 CA 服务器上运行，而不是一个单独的机构。

> 另外，这部分内容还包含证书申请与吊销流程、证书链与证书验证流程，由于不是本文重点，所以此处不再赘述，有兴趣的读者请自行查询相关内容。

#### 1.3 RA

**概述**

注册机构（RA）是用户与证书颁发机构（CA）之间的重要桥梁。RA 负责获取和认证用户的身份，然后向 CA 发送申请证书的请求。在较小规模的 PKI 系统中，RA 的功能可以整合到 CA 中以节约成本。然而，为了提高 PKI 系统的安全性，国际标准建议使用独立的 RA 来实现用户注册功能。

**功能与角色**

- **身份认证：** RA 负责验证用户的身份信息，确保申请证书的用户身份真实可信。
- **申请证书：** 经过身份认证后，RA 向 CA 发送证书申请请求，并跟踪申请的进展和结果。

**建议与实践**

在实际应用中，尽管将 RA 功能整合到 CA 中可以节约成本，但为了增强系统的安全性和信任度，国际 PKI 标准建议保持 RA 和 CA 的独立性。这种分离不仅有助于分散风险，还能提升整个 PKI 系统的安全性和可靠性。

#### 1.4 证书发布系统

**概述**

证书发布系统负责实现数字证书的发放和管理。它通过 LDAP 服务器向用户提供证书和证书吊销列表（CRL）的下载服务。

**功能与实现**

- **证书发放：** 将经过 CA 签发的证书发布给用户。
- **证书与 CRL 下载：** 用户可以通过 LDAP 服务器下载所需的证书和 CRL，以便进行身份验证和证书状态检查。

#### 1.5 PKI 应用

**概述**

PKI 应用是基于 PKI 的证书和密钥来实现特定功能的一些系统。这些应用利用 PKI 的数字证书进行身份认证，并使用非对称加密进行密钥协商。

**典型应用**

- VPN（虚拟专用网络）：通过 PKI 实现安全的远程访问，利用数字证书验证用户身份，并建立加密通信通道。
- TLS（传输层安全协议）：保护互联网通信安全，基于 PKI 的数字证书进行服务器和客户端的身份验证，然后通过非对称加密完成密钥协商，确保数据传输的机密性和完整性。

**实现原理**

这些系统通过以下步骤实现安全通信：

1. 身份认证：使用 PKI 的数字证书来验证通信双方的身份。
2. 密钥协商：通过非对称加密算法协商生成对称加密密钥，用于后续的数据加密传输。

### 2. PKI 与区块链

**概述**

在公链中，节点可以自由地加入或退出网络，无需任何门槛。但在联盟链中，节点的准入需要授权，并且需要对节点进行访问控制。仅使用数字签名技术无法实现身份认证和访问控制，因此需要通过数字证书将密钥与密钥拥有者的身份信息联系起来。

**数字证书在联盟链中的作用**

联盟链中的节点主要与链内其他节点进行通信，因此节点证书可以由区块链内部被大多数节点信任的一个或多个 CA（证书颁发机构）生成，而不必依赖外部第三方可信 CA。这样可以满足联盟链网络中各节点之间的身份认证需求。

**MSP（Member Service Provider）**

除了 CA，联盟链还需要一个实现密钥生成与管理等功能的服务，这个服务通常称为 MSP。MSP 是区块链上的一个身份认证和权限管理的抽象逻辑组件，负责认证所有可能与网络建立联系的节点，确保只有经过授权的节点才能通过验证。

**MSP 的功能和配置**

- **身份认证：** 通过维护一个可信 CA 列表（包括 CA 证书）和 CRL（证书吊销列表），MSP 在验证节点身份时发挥重要作用。证书验证过程是一个“证书链”验证过程，直到找到一个颁发者是区块链上的可信 CA，证书验证才完成。
- **权限管理：** MSP 可以配置相应的安全策略，如对 RPC 请求来源的验证、对等节点身份的验证、是否采用分布式 CA 等。
- **密钥管理：** MSP 初始化后，可以实现签名、验签、密钥生成等具体功能，确保节点之间的通信安全和数据完整性。

#### 2.1 区块链中的 CA

**概述**

在区块链中，CA（证书颁发机构）主要分为两种：本地 CA 和远程 CA。前者由本地系统掌握私钥，后者由远程系统掌握私钥，如中国金融认证中心（CFCA）。根据是否需要配置相同的可信 CA 列表，区块链中的 CA 又可分为中心式 CA 和分布式 CA。趣链区块链平台支持这两种类型的 CA。

**中心式 CA**

在中心式 CA 中，所有节点都需要配置一个 CRL（证书吊销列表）及一个相同的可信 CA 列表（内容为 CA 证书列表）。这些证书可以是本地 CA 或远程 CA 颁发的。在节点通信时，每个节点根据本地的 CA 列表验证对方节点发来的证书，同时发送自己的证书给对方进行验证。

**分布式 CA**

在分布式 CA 中，虽然所有节点仍需配置 CRL，但无需为所有节点配置相同的可信 CA 列表。相反，每个节点只需配置网络内所有 CA 对本节点颁发的证书。在与不同节点通信时，使用相应节点支持的 CA 颁发的证书。为了实现节点的动态添加，分布式 CA 只支持本地 CA，每个节点本质上都是一个 CA。新节点加入后，需要向网络中的所有 CA 申请证书，并记录在指定文件中，这样节点在重启后可以顺利地与其他节点进行通信。

#### 2.2 不同类型的证书

为了实现对节点和其他外部连接的访问控制，通常需要设计多种证书类型，节点持有不同类型的证书，代表拥有不同权限。例如，趣链区块链平台支持三种证书类型：

SDK 证书、节点准入证书、CA 证书。使用 SDK 访问链上数据时，需要提供 SDK 证书，否则不能建立连接；普通节点在加入区块链网络时，需要提供节点准入证书；

验证这些证书需要 CA 证书支持。

## 五、Merkle 树

Merkle 树，也称为哈希树，是一种用于存储哈希值的数据结构。其叶子节点包含原始数据的哈希值，非叶子节点则包含其子节点串联字符串的哈希值。

Merkle 树可以被视为哈希列表的扩展，通过构造树形结构的哈希验证路径，可以对完整数据中的单个分支进行独立验证，从而提高了完整性验证的效率。这种结构使得在区块链等系统中，可以高效地验证数据的完整性和一致性，而无需检查整个数据集。

### 1. 基于 hash 列表的完整性校验

**概述**

哈希列表用于在 P2P 网络中进行数据传输的完整性校验。在 P2P 网络中，原始大数据块被分割成多个小数据块以实现分布式下载，最终合成完整的大数据块。通过构造哈希列表，可以有效地校验多个小数据块的完整性。

**过程**

1. **哈希计算：** 首先，计算每个小数据块的哈希值。这些哈希值再级联在一起进行一次哈希计算，得到哈希列表的根哈希值。
2. **下载与校验：**

   - 下载数据时，首先从可信的数据源获取正确的根哈希值。
   - 利用这个根哈希值，可以校验哈希列表的正确性。
   - 通过验证哈希列表，进而校验整个数据块的完整性。

这种方法确保了在数据分布式下载过程中，每个小数据块的完整性和正确性，最终保证整个大数据块的可靠性。

结构如下图

![](static/D7RwbXVkyoTXW0xL8UUcXHvQnSf.png)

### 2.基于 Merkle 树的完整性校验

**概述**

Merkle 树的结构与哈希列表类似，但其相邻节点会合并计算生成一个新的哈希值作为上一层的节点。如果这一层是奇数个节点，则最后一个节点的哈希值直接上升至上一层。通过这种方式，最终会获得一个根节点和所有内部节点。

**过程**

1. **树的构建：**

   - 计算每个叶子节点（即原始数据块）的哈希值。
   - 将相邻的哈希值两两合并，再次计算哈希值，生成新的父节点。
   - 如果某一层节点数为奇数，则直接将最后一个节点的哈希值上升至上一层。
   - 重复此过程，直到生成单一的根节点。
2. **下载与校验：**

   - 在 P2P 网络下载之前，先从可信节点获取文件的 Merkle 树根节点。
   - 从其他不可信节点获取 Merkle 树的子节点。
   - 不同于哈希列表，Merkle 树允许下载和验证单独的分支。如果某个分支节点损坏，只需重新下载该分支节点。
   - 当文件较大时，Merkle 树的效率显著高于哈希列表，因为它可以快速定位并校验特定数据块的完整性。

这种结构确保了在数据传输过程中，每个数据块的完整性和正确性，显著提高了文件下载的效率和可靠性。

Merkle 树多指完全二叉树，也可以是完全多叉树。结构如下图

![](static/SPVnbeYybopeUTxyKT4cej7rn9b.png)

## 六、数字签名技术

**概述**

数字签名技术利用私钥对数据进行加密运算，生成一串字符，以替代手写签名或印章。它用于确认消息来源，防止欺诈或消息伪造。

### 一、原理

数字签名技术基于公钥密码算法（非对称加密），在身份验证、数据源认证、完整性保护和不可否认性方面发挥重要作用。数字签名主要包括两部分：签名生成和签名验证。

签名生成与验证过程：

1. **签名生成：**

   - 选择一种公钥算法。
   - 使用私钥对原数据进行加密，生成签名字符串。
2. **签名验证：**

   - 验证方通过可信途径获取签名者的公钥，例如通过公钥数字证书。
   - 接收到签名后，计算原数据的摘要。
   - 使用公钥和验证算法解密签名字符串。
   - 比较解密后的数据摘要与接收到的原数据摘要，若一致则签名有效。

**详细步骤：**

1. 验证方通过可信途径获得签名者的公钥，例如通过公钥数字证书。
2. 接收到签名后，计算原数据的摘要，并使用验证算法进行验证，通过摘要比对判断签名的有效性。

### 二、可选方案

- **RSA 签名：** 基于 RSA 算法，广泛应用于各种数字签名和加密场景。
- **椭圆曲线签名方案（ECDSA）：** 基于椭圆曲线密码学，提供更高效的安全性，适用于资源受限的环境。

## 七、零知识证明（Zero—Knowledge Proof，ZKP）

**概述**

零知识证明（ZKP）是在 20 世纪 80 年代初提出的，它允许证明者向验证者证明自己拥有某个秘密，而不泄露该秘密本身，即向外界透露的「知识」为零。零知识证明分为交互式和非交互式两种类型。

**零知识证明的三个重要性质**

1. **完备性（Completeness）：** 如果证明者确实拥有相应的知识，那么他们能够通过验证者的验证，即证明者有足够大的概率使验证者确信。
2. **可靠性（Soundness）：** 如果证明者没有相应的知识，则无法通过验证者的验证，即证明者欺骗验证者的概率可以忽略不计。
3. **零知识性（Zero-Knowledge）：** 在交互过程中，证明者仅向验证者透露是否拥有相应知识，而不会泄露任何关于知识的额外信息。

**关键点与应用场景**

从零知识证明的定义中可以提取两个关键词：“不泄露信息”和“证明论断有效”。基于这两个特点，零知识证明在区块链上有两个主要应用场景：

1. **隐私保护：**

   - 在隐私场景中，利用零知识证明的“不泄露信息”特性，可以在不泄漏交易细节（如接收方、发送方、交易金额）的情况下，证明区块链上的资产转移是有效的。
2. **扩容：**

   - 在扩容场景中，主要关注零知识证明的“证明论断有效”特性。由于链上资源有限，需要将大量计算迁移到链下进行，因此需要一种技术来证明链下发生的动作是可信的。零知识证明能够为链下可信计算提供支持。

### 1. 交互式零知识证明（Interactive Zero-Knowledge, IZK）

交互式零知识证明是指证明者和验证者双方按照一个协议，通过一系列交互，最终验证者能够得出一个明确的结论，即证明者是否掌握某个秘密。

### 2. 非交互式零知识证明（Non-Interactive Zero-Knowledge, NIZK）

交互式零知识证明（IZK）协议依赖于验证者的随机尝试，需要证明者和验证者进行多次交互才能完成验证。而非交互式零知识证明（NIZK）将交互次数减少到一次，实现了离线证明和公开验证。

> 区块链系统使用的就是这种，因为在区块链系统中，不能假设双方一直在线进行交互，在区块链网络上，证明者只要向全网广播一条证明交易，网络上的矿工在将
> 这条交易打包到区块中的时候就帮验证者完成了零知识证明的校验。

### 3. 发展历史

- 1985 年：S. Goldwasser、S. Micali 和 C. Rackoff 首次提出了零知识证明（Zero-Knowledge Proof, ZKP）的概念。
- 2010 年：Groth 实现了首个基于椭圆曲线双线性映射的常数大小的非交互式零知识证明协议。该协议经过不断优化，最终演变成区块链中著名的零知识证明协议 SNARKs。
- 2013 年：Pinocchio 协议实现了分钟级别的证明、毫秒级别的验证，证明大小不到 300 字节，将零知识证明从理论应用到实践。Zcash 使用的 SNARKs 正是基于 Pinocchio 的改进版。
- 2014 年：名为 Zerocash 的加密货币使用了一种特殊的零知识证明工具 zk-SNARKs（Zero-Knowledge Succinct Non-interactive Arguments of Knowledge），实现了对交易金额和交易双方的完全隐藏，强调隐私和交易透明的可控性。
- 2017 年：Zerocash 团队提出了将 zk-SNARKs 与智能合约结合的方案，使得交易在众目睽睽之下隐身，打造保护隐私的智能合约。

**零知识证明开发工具**

为了满足零知识证明技术的广泛应用需求，已经开发出多个用于实现 zk-SNARK 零知识证明协议的开源算法库，包括 **libsnark**、**bellman** 和 **ZoKrates** 等。

### 4. 区块链如何应用零知识证明

#### 4.1 隐私

在比特币交易过程中，为验证一笔交易是否合法，实际上只需验证以下三件事：

1. 发送方确实拥有足够的资金。
2. 发送方转出的金额和接收方收到的金额一致。
3. 发送方的资金确实被销毁。

在整个证明过程中，矿工实际上并不关心具体的交易金额、发送者身份或接收者身份。**矿工只关心系统中的资金是否守恒**。Zcash（大零币）正是基于这一思路，实现了隐私交易。

#### 4.2 扩容

早期公链项目的 TPS（每秒交易数）非常低，例如比特币的 TPS 约为 7，以太坊的 TPS 约为 15。这意味着以太坊每秒只能处理 15 笔交易，如此低的 TPS 严重限制了区块链应用的大规模落地。因此，研究区块链扩容的问题变得至关重要，目标是提高链上的 TPS。

然而，区块链扩容受限于 Vitalik 提出的不可能三角理论，即区块链系统设计无法同时兼顾可扩展性、去中心化和安全性，三者只能取其二。这一结论虽然令人失望，但我们必须认识到，任何事物都有其边界。公链不应试图承担所有任务，而应专注于其核心使命：“公链是以最高效率达成共识的工具，能够以最低成本构建信任”。

作为共识的工具和信任的引擎，公链不应为了可扩展性而放弃去中心化和安全性。那么，如何在保持去中心化和安全性的同时，提升公链的 TPS 呢？一个有效的方法是将大量的工作放到链下处理，只将最重要的数据提交到区块链主链上，让所有节点都能够验证这些链下工作的准确性和可靠性。

区块链技术的发展也是如此，在底层区块链（Layer 1）上构建一个扩展层（Layer 2）。Layer 1 负责确保安全和去中心化，做到全球共识，并作为“加密法院”，通过智能合约设计的规则进行仲裁，以经济激励的形式将信任传递到 Layer 2 上。而 Layer 2 追求极致的性能，虽然只能实现局部共识，但能够满足各种商业场景的需求。

**链下扩容**

ZK-Rollup 是一种基于零知识证明的二层扩容方案。ZK-Rollup 方案起源于 2018 年下半年，由 Barry Whitehat 和 Vitalik 提出。Rollup 意为“卷起”和“汇总”，将大量交易“卷起/汇总”打包成一个交易。

**ZK-Rollup 的原理**

ZK-Rollup 的原理可以简要概述为：在链下进行复杂的计算和证明生成，链上进行证明的校验并存储部分数据以保证数据可用性。ZK-Rollup 的数据可用性允许任何人根据链上存储的交易数据，还原出账户的全局状态。

## 八、Base58 编码方案

**概述**

Base58 是一种 58 进制的编码方案，与 Base64 类似，基于 58 个可打印字符来表示二进制数据。这些字符包括阿拉伯数字和大小写英文字母。

**特点**

相比于 Base64，Base58 去掉了 6 个易混淆的字符：数字 0、大写 O、小写 l、大写 I 以及 +/，以便在任何字体中都能肉眼区分这些字符。这种设计使得 Base58 编码在需要高可读性的场景中（如区块链地址和密钥）更加实用。

> Base58 和 Base64 的缺点是会造成信息冗余，输出比输入大许多，所以这种编码方案只适合小数据。而且 Base58 与 Base64 不同的是，前者采用大数进制转换，
> 效率更低，所以使用场景更少。

Base64 普通应用于 URL，短文本，图片；Base58 一般用在比特币地址、私钥和脚本哈希场景。